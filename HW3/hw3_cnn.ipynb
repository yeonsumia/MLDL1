{"cells":[{"cell_type":"markdown","id":"b945e8df","metadata":{"id":"b945e8df"},"source":["# Convolution Function"]},{"cell_type":"code","execution_count":null,"id":"f7c5f658","metadata":{"id":"f7c5f658"},"outputs":[],"source":["import numpy as np\n","\n","def Convolution(image, filter, stride=1, padding=0):\n","    \"\"\"\n","    Question (a)\n","    Implement your own conv function which performs convolution operation without using any neural network packages.\n","    Make sure to handle all possible edge cases to receive full credits as your implementation will be tested with 20 test cases (1 pt for each test case).\n","    Keep in mind that height and width of the given image or filter are not always the same.\n","\n","    Inputs\n","    - image: 2D numpy array \n","    - filter: 2D numpy array\n","    - stride, padding: integers\n","\n","    Outputs:\n","    - 2D numpy array : convolution results of the given image and filter..\n","    - Return None if stride is not compatible. (ex. image of 5*5 with filter 2*2 with stride 2, padding 0)\n","    - Return None if filter is larger than the given image.\n","    \"\"\"\n","\n","    ### COMPLETE HERE ###\n","    \n","    ### COMPLETE HERE ###\n","    \n","    return output"]},{"cell_type":"code","execution_count":null,"id":"0OOzxnZAMczU","metadata":{"id":"0OOzxnZAMczU"},"outputs":[],"source":["Convolution(np.array([[1, 2, 3, 2, 1], [2, 3, 4, 5, 6], [-1, -2, -3, -4, -5], [0, 0, 1, 0, 0], [7, 1, 7, 1, 7]]), np.array([[1, 0], [0, 1]]), stride=3, padding=1)\n","## Expected result:\n","# array([[ 1.,  2.],\n","#        [ 0., -3.]])"]},{"cell_type":"markdown","id":"mDOdbok4zVE4","metadata":{"id":"mDOdbok4zVE4"},"source":["# Colab Setup"]},{"cell_type":"code","execution_count":null,"id":"-NvjxSCiMfMq","metadata":{"id":"-NvjxSCiMfMq"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"oS5qDEF5MftN","metadata":{"id":"oS5qDEF5MftN"},"outputs":[],"source":["\"\"\"\n","Change directory to where this file is located\n","\"\"\"\n","# %cd 'COPY&PASTE FILE DIRECTORY HERE'"]},{"cell_type":"markdown","id":"giBbJLW-zhS-","metadata":{"id":"giBbJLW-zhS-"},"source":["# Import Modules"]},{"cell_type":"code","execution_count":null,"id":"KjGAWailzgP1","metadata":{"id":"KjGAWailzgP1"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, datasets"]},{"cell_type":"code","execution_count":null,"id":"55f78236","metadata":{"id":"55f78236"},"outputs":[],"source":["\"\"\"\n","import modules you need\n","\"\"\"\n"]},{"cell_type":"markdown","id":"2f33b210","metadata":{"id":"2f33b210"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"id":"b7112995","metadata":{"id":"b7112995"},"outputs":[],"source":["def plot_dataset(dataloader, grid_width=8, grid_height=2, figure_width=12, figure_height=3, y_hats=None):\n","    \"\"\"\n","    Plots image and labels.\n","\n","    Do NOT modify this function.\n","    \"\"\"\n","    images, labels = next(iter(dataloader))\n","    f, ax = plt.subplots(grid_height, grid_width)\n","    f.set_size_inches(figure_width, figure_height)\n","    img_idx = 0\n","    for i in range(0, grid_height):\n","        for j in range(0, grid_width):\n","            image = images[img_idx]\n","            label = labels[img_idx]\n","            title_color = 'k'\n","            if y_hats is None:\n","                label_idx = int(label)\n","            else:\n","                label_idx = int(y_hats[img_idx])\n","                if int(labels[img_idx]) != label_idx:\n","                    title_color = 'r'\n","            label = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'][label_idx]\n","            ax[i][j].axis('off')\n","            ax[i][j].set_title(label, color=title_color)\n","            ax[i][j].imshow(np.transpose(image, (1, 2, 0)), aspect='auto')\n","            img_idx += 1\n","        plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0.25)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"-ANUeGuyNGua","metadata":{"id":"-ANUeGuyNGua"},"outputs":[],"source":["def train(model, train_loader, optimizer):\n","    \"\"\"\n","    Trains the model with training data.\n","\n","    Do NOT modify this function.\n","    \"\"\"\n","    model.train()\n","    tqdm_bar = tqdm(enumerate(train_loader))\n","    for batch_idx, (image, label) in tqdm_bar:\n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(image)\n","        loss = criterion(output, label)\n","        loss.backward()\n","        optimizer.step()\n","        tqdm_bar.set_description(\"Epoch {} - train loss: {:.6f}\".format(epoch, loss.item()))\n","\n","\n","def evaluate(model, test_loader):\n","    \"\"\"\n","    Evaluates the trained model with test data.\n","\n","    Do NOT modify this function.\n","    \"\"\"\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for image, label in tqdm(test_loader):\n","            image = image.to(DEVICE)\n","            label = label.to(DEVICE)\n","            output = model(image)\n","            test_loss += criterion(output, label).item()\n","            prediction = output.max(1, keepdim=True)[1]\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\n","    \n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy"]},{"cell_type":"markdown","id":"4a242b15","metadata":{"id":"4a242b15"},"source":["# CIFAR-10 Data Augmentation"]},{"cell_type":"code","execution_count":null,"id":"aSH0yYaO2tBH","metadata":{"id":"aSH0yYaO2tBH"},"outputs":[],"source":["def gaussian_smoothing(image, filter_size=3, sigma=1.0):\n","    \"\"\"\n","    Inputs\n","    - image: an input image of shape (32,32,3).\n","    Returns\n","    - image: image blurred with a Gaussian Filter.\n","\n","    Do NOT modify this function.\n","    \"\"\"\n","    center = (filter_size-1)/2\n","    gaussian_filter = np.zeros((filter_size, filter_size))\n","    for row in range(filter_size):\n","        for col in range(filter_size):\n","            gaussian_filter[row, col] = np.exp((-(row-center) ** 2 - (col-center) ** 2) / (2 * sigma ** 2)) / (2 * np.pi * sigma ** 2)\n","    gaussian_filter = gaussian_filter / np.sum(gaussian_filter)\n","    image = cv2.filter2D(image, -1, gaussian_filter)\n","    return image\n","\n","def color_jitter(image):\n","    \"\"\"\n","    Inputs\n","    - image: an input image of shape (32,32,3).\n","    Returns\n","    - image: image blurred with a Gaussian Filter.\n","\n","    Do NOT modify this function.\n","    \"\"\"\n","    image = cv2.convertScaleAbs(image, alpha=1.5, beta=20)\n","    return image\n","\n","def custom_augmentation(image):\n","    \"\"\"\n","      Define your own augmentation without using neural network libraries.\n","\n","      Extra Credit Question (b)\n","      - You can use opencv library for this question.\n","\n","      Inputs\n","      - image: an input image of shape (3,32,32).\n","      Returns\n","      - image: image after applying your custom augmentation.\n","    \"\"\"\n","    ### COMPLETE HERE ###\n","\n","    ### COMPLETE HERE ###\n","\n","    return image"]},{"cell_type":"code","execution_count":null,"id":"VNXqg19fvtC5","metadata":{"id":"VNXqg19fvtC5"},"outputs":[],"source":["\"\"\"\n","Visualize how the augmentations are applied to a single image.\n","You can run this block of code to check how your custom augmentation function from (b) is applied.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","raw_test = datasets.CIFAR10(root=\"./CIFAR_10\", train=False, download=True)\n","\n","f, ax = plt.subplots(1, 5)\n","f.set_size_inches(12, 3)\n","x = raw_test[0][0]\n","x = np.array(x)\n","g = gaussian_smoothing(x)\n","j = color_jitter(x)\n","c = custom_augmentation(x)\n","title = ['original image', 'gaussian filter', 'color jitter', 'custom augmentation', 'original image']\n","for i, img in enumerate([x, g, j, c, x]):\n","    ax[i].imshow(img)\n","    ax[i].axis('off')\n","    ax[i].set_title(title[i], color='k')"]},{"cell_type":"code","execution_count":null,"id":"24wjKV1OCiP5","metadata":{"id":"24wjKV1OCiP5"},"outputs":[],"source":["### \n","# Extra Credit Question (b)\n","# (1) Briefly describe what your custom_augmentation function does.\n","# (2) Using the visualization results shown above, explain why you believe your custom augmentation function is useful for image classification task.\n","###"]},{"cell_type":"markdown","id":"weSZOvYtBtP0","metadata":{"id":"weSZOvYtBtP0"},"source":["Write your answer to question (b) in this cell."]},{"cell_type":"code","execution_count":null,"id":"0SQnrsBsUmJX","metadata":{"id":"0SQnrsBsUmJX"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, train, prob=0.5, data_dir=\"./CIFAR_10\"):\n","        \"\"\"\n","        Do NOT modify this method.\n","        \"\"\"\n","        self.data = datasets.CIFAR10(root=data_dir, train=train, download=True)\n","        self.prob = prob\n","\n","    def __len__(self):\n","        \"\"\"\n","        Do NOT modify this method.\n","        \"\"\"\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Do NOT modify this method.\n","        \"\"\"\n","        return self.data[idx]\n","    \n","    def transform(self, image):\n","        \"\"\"\n","          Apply stochastic data augmentation to the given image.\n","\n","          Question (c)\n","          - Convert the given RGB image into BGR scale using opencv library.\n","          - Apply random augmentation (gaussian smoothing and color jitter, custom_augmentation if implemented).\n","            - Random augmentation is applied with the probability of self.prob.\n","            - If self.prob = 0.5, 5 out of 10 images will be augmented on average.\n","          - Convert the augmented image back to RGB scale for training.\n","\n","          Inputs\n","          - image: numpy array of an input image of shape (32,32,3).\n","          Returns\n","          - image: numpy array of the augmented input image with shape (32,32,3).\n","        \"\"\"\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","        ### COMPLETE HERE ###\n","\n","        ### COMPLETE HERE ###\n","        \n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        return image\n","\n","    def collate_fn(self, data):\n","        \"\"\"\n","        Creates a batch of images and label tensors.\n","\n","        Question (d)\n","        - Convert each image in the batch from PIL image to numpy array.\n","        - Transform the image using self.transform method to apply random augmentation.\n","        - Normalize the transformed image by mapping the range [0, 255] to range [0, 1].\n","        - Transpose the (H * W * C) format of the image into (C * H * W) format.\n","          - To be specific, the dimension of the original image is (32, 32, 3).\n","          - We want the dimension of the transposed image to be (3, 32, 32).\n","        - Convert the batch of preprocessed images into PyTorch float tensors.\n","        - Convert the batch of labels into PyTorch long tensors.\n","        - Do NOT use torchvision.transforms library!\n","\n","        Inputs\n","        - list of tuples, each containing a PIL image and an integer label\n","        - number of tuples in the list == BATCH SIZE\n","        Returns\n","        - batch of image tensors, batch of label tensors\n","        - size: (BATCH, CHANNEL, HEIGHT, WIDTH), (BATCH)\n","        \"\"\"\n","        batch_x, batch_y = [], []\n","\n","        ### COMPLETE HERE ###\n","        \n","        ### COMPLETE HERE ###\n","\n","        return batch_x, batch_y\n","    "]},{"cell_type":"code","execution_count":null,"id":"DpcJAAqWe-uM","metadata":{"id":"DpcJAAqWe-uM"},"outputs":[],"source":["\"\"\"\n","Plot some example images and class labels without applying data augmentation.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","raw_test_dataset = CustomDataset(train=False, prob=0, data_dir=\"./CIFAR_10\")\n","raw_test_loader = DataLoader(dataset=raw_test_dataset, batch_size=16, shuffle=False, collate_fn=raw_test_dataset.collate_fn)\n","\n","plot_dataset(raw_test_loader)"]},{"cell_type":"code","execution_count":null,"id":"TCa4Ay4mWws9","metadata":{"id":"TCa4Ay4mWws9"},"outputs":[],"source":["\"\"\"\n","Same examples after applying data augmentation with 50% probability.\n","If your transform (c) and collate_fn (d) methods have been implemented well, some of the results should look different from the ones above.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","train_dataset = CustomDataset(train=True, prob=0.5)\n","test_dataset = CustomDataset(train=False, prob=0.5)\n","\n","BATCH_SIZE = 64\n","\n","train_loader = DataLoader(dataset=train_dataset, \n","                          batch_size=BATCH_SIZE, \n","                          shuffle=True, \n","                          collate_fn=train_dataset.collate_fn)\n","test_loader = DataLoader(dataset=test_dataset, \n","                         batch_size=BATCH_SIZE, \n","                         shuffle=False, \n","                         collate_fn=test_dataset.collate_fn)\n","\n","plot_dataset(test_loader)"]},{"cell_type":"markdown","id":"2eeea83e","metadata":{"id":"2eeea83e"},"source":["# ConvNet Image Classification"]},{"cell_type":"code","execution_count":null,"id":"P0xUGjocL4OH","metadata":{"id":"P0xUGjocL4OH"},"outputs":[],"source":["### \n","# Question (e)\n","# Train your ConvNet to achieve test accuracy above 60%\n","# You can try or add other training options such as SGD or callbacks to schedule learning rates if you want.\n","###"]},{"cell_type":"code","execution_count":null,"id":"c4d35830","metadata":{"id":"c4d35830"},"outputs":[],"source":["class ConvNet(nn.Module):\n","    \"\"\"\n","    Builds a ConvNet model.\n","\n","    Question (e)\n","    - things that might be useful...\n","    - stack [Conv2D + Conv2D + MaxPool2D] at least three times, \n","    - follwed by at least three Linear layers.\n","    - 3x3 filter is enough, but feel free to use larger filter size.\n","    - channels used: [10, 32, 64, 128, 256, 512, 1024]\n","    - you can choose smaller or larger channel size as well.\n","    - The model may include BatchNormalization, regularizers, and Dropout, but they are not necessary.\n","    \"\"\"\n","    def __init__(self):\n","        \"\"\"\n","        Define the layers that you would like to use in your model.\n","        \"\"\"\n","        super(ConvNet, self).__init__()\n","\n","        ### COMPLETE HERE ###\n","\n","        ### COMPLETE HERE ###\n","    \n","    def forward(self, x):\n","        \"\"\"\n","        Apply forward pass of the given batch of input images.\n","        Inputs\n","        - x: batch of input images.\n","        Returns\n","        - softmax probabilites of the input image for each class label\n","        \"\"\"\n","\n","        ### COMPLETE HERE ###\n","        \n","        ### COMPLETE HERE ###\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"VbHlUuyTdhK2","metadata":{"id":"VbHlUuyTdhK2"},"outputs":[],"source":["\"\"\"\n","Make sure your runtime type is GPU and you are using PyTorch version higher than 1.8!\n","\n","Do NOT modify.\n","\"\"\"\n","\n","DEVICE = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n","print(\"Using PyTorch version: {}, Device: {}\".format(torch.__version__, DEVICE))"]},{"cell_type":"code","execution_count":null,"id":"HA_mGa0orKj5","metadata":{"id":"HA_mGa0orKj5"},"outputs":[],"source":["\"\"\"\n","Load your customized model \"ConvNet\" and its training settings.\n","You may choose the number of epochs that you would like to train.\n","You might want to use different optimizers or learning rates.\n","\"\"\"\n","\n","EPOCHS = 10\n","model = ConvNet().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","print(model)"]},{"cell_type":"code","execution_count":null,"id":"sjeFjn0qrPRK","metadata":{"id":"sjeFjn0qrPRK"},"outputs":[],"source":["\"\"\"\n","Train your model \"ConvNet\" with the augmented CIFAR-10 dataset.\n","Upon successful training, test accuracy of your model should be above 70%.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train(model, train_loader, optimizer)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","    print(\"\\n[EPOCH: {}], \\tModel: ConvNet, \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n","        epoch, test_loss, test_accuracy))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"hw3_cnn.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}
