{"cells":[{"cell_type":"markdown","metadata":{"id":"xvh969t1VJzj"},"source":["# Environment Setup"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2652,"status":"ok","timestamp":1654088907612,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"kO4EhYqCTdbt","outputId":"393c5a58-2cc0-4842-ff31-3269ff8e1315"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1654088755140,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"gyi5Ljv8TpjO","outputId":"6b67d667-c3a7-42f6-ecb7-9fca63dea4d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/study/Github/MLDL1/HW4\n"]}],"source":["\"\"\"\n","Change directory to where this file is located\n","\"\"\"\n","%cd /content/drive/MyDrive/study/Github/MLDL1/HW4"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3355,"status":"ok","timestamp":1654088761539,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"fDk49qpsU_BK","outputId":"c11f07de-2e0a-4975-a0d6-213defcbacad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n","Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.2.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n"]}],"source":["! pip install torchdata"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3062,"status":"ok","timestamp":1654082593934,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"NMAuwnOwVBOu"},"outputs":[],"source":["import math\n","import numpy as np\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchtext\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.data.functional import to_map_style_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654069684773,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"I6fOONHU7aMR","outputId":"6ea7c73a-f7a5-4251-9836-f4b49c1d5d8d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nimport modules you need\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","import modules you need\n","\"\"\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654082594364,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"yn5FYiiQVC2k","outputId":"2beb821b-3d2f-47c7-9654-b84a94eab8dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using PyTorch version: 1.11.0+cu113, Device: cpu\n","Using torchtext version: 0.12.0\n"]}],"source":["DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","print(\"Using PyTorch version: {}, Device: {}\".format(torch.__version__, DEVICE)) ## should be 1.11.0 and cuda\n","print(\"Using torchtext version: {}\".format(torchtext.__version__)) ## should be 0.12.0"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":296,"status":"ok","timestamp":1654082597609,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"YBmGs2zeOpf7"},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"markdown","metadata":{"id":"E4E1p3w-VLTq"},"source":["# Load Data"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":10370,"status":"ok","timestamp":1654088795215,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"NXSORPxqn7lU"},"outputs":[],"source":["\"\"\"\n","Load AG_NEWS dataset and set up the tokenizer and encoder pipeline.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","train_data, test_data = torchtext.datasets.AG_NEWS(root='./data')\n","\n","tokenizer = get_tokenizer('basic_english')\n","\n","def tokens(data_iter):\n","    for _, text in data_iter:\n","        yield tokenizer(text)\n","\n","encoder = build_vocab_from_iterator(tokens(train_data), specials=[\"<unk>\"])\n","encoder.set_default_index(encoder[\"<unk>\"])\n","\n","text_pipeline = lambda x: encoder(tokenizer(x))\n","label_pipeline = lambda x: int(x) - 1"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1654082615918,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"jpb0L6hvmh2M"},"outputs":[],"source":["def collate_batch(batch):\n","    \"\"\"\n","    Creates a batch of encoded text, label and token length tensors.\n","\n","    Question (a)\n","    - Length of token sequence in each batch is determined by \n","      the average of token length of all sequences in each batch.\n","    - Text tensors are stacked with dimension of (TOKEN_LENGTH, BATCH),\n","      for easier process in RNN model.\n","    - Token length tensors are used to index the last valid hidden token for classification.\n","\n","    Inputs\n","    - list of tuples, each containing an integer label and a text input\n","    - number of tuples in the list == BATCH SIZE\n","    Returns\n","    - text_list: batch of encoded long type text tensors with size (TOKEN_LENGTH, BATCH)\n","    - label_list: batch of label tensors with size (BATCH)\n","    - len_list: batch of token length tensors with size (BATCH)\n","    \"\"\"\n","\n","    text_list, label_list, len_list = [], [], []\n","    \n","    ### COMPLETE HERE ###\n","    tmp_text_list = []\n","    for (label, text) in batch:\n","      processed_txt = torch.tensor(text_pipeline(text), dtype=torch.int64)\n","      len_list.append(processed_txt.size(0))\n","      tmp_text_list.append(processed_txt)\n","      label_list.append(label_pipeline(label))\n","      \n","    TOKEN_LENGTH = int(sum(len_list) / len(len_list))\n","\n","    for processed_txt in tmp_text_list:\n","      if processed_txt.size(0) >= TOKEN_LENGTH:\n","        processed_txt = processed_txt[:TOKEN_LENGTH]\n","      else:\n","        processed_txt = torch.cat([processed_txt, torch.zeros(TOKEN_LENGTH-processed_txt.size(0))])\n","      text_list.append(processed_txt)\n","\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    text_list = torch.stack(text_list, dim=1).long() # append text in dim=1 to make size=(TOKEN_LENGTH, BATCH) \n","    len_list = torch.tensor(len_list, dtype=torch.int64)\n","    ### COMPLETE HERE ###\n","    \n","    assert text_list.size(1) == len(batch)\n","\n","    return text_list, label_list, len_list"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4514,"status":"ok","timestamp":1654082623733,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"nJXoUuq0NgiV"},"outputs":[],"source":["\"\"\"\n","Load the data loader.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","BATCH_SIZE = 512\n","\n","train_dataset = to_map_style_dataset(train_data)\n","test_dataset = to_map_style_dataset(test_data)\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)\n","valid_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1654082626432,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"4X2_aQKhxWV3","outputId":"a495410e-27b4-4d65-87e7-fdc505c6d8c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1173, 39989,  3049,  ..., 19608,  4203,  1174],\n","        [ 1710,  2090,   190,  ...,    12,   142,   626],\n","        [  337,   575,    12,  ...,     9,     3,  6085],\n","        ...,\n","        [ 1591,  7253,   327,  ...,    53,     6,   376],\n","        [  218,  5350,  3813,  ...,  2961,   405,  6330],\n","        [    1,  1287,  3049,  ..., 19608,     7, 86540]])\n","tensor([2, 1, 2, 3, 3, 1, 2, 2, 3, 3])\n","tensor([48, 29, 39, 47, 40, 52, 63, 44, 38, 51])\n"]}],"source":["\"\"\"\n","Print out the first batch in the train loader.\n","Check if the collate function is implemented correctly.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","for batch_x, batch_y, len_x in train_dataloader:\n","    print(batch_x[:10])\n","    print(batch_y[:10])\n","    print(len_x[:10])\n","    break"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"elapsed":7621,"status":"ok","timestamp":1654082635959,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"95s-BUHc37O_","outputId":"f0c77a2b-5112-41a0-bab6-8953d98f8151"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([  1.,   0.,   0.,  73.,   0.,   0., 136.,   0.,   0.,  25.]),\n"," array([41. , 41.3, 41.6, 41.9, 42.2, 42.5, 42.8, 43.1, 43.4, 43.7, 44. ]),\n"," <a list of 10 Patch objects>)"]},"metadata":{},"execution_count":11},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["\"\"\"\n","Plot the sequence length distribution of the batches in the train dataloader.\n","Make sure that all batches have difference sequence lengths.\n","\n","Do NOT modify.\n","\"\"\"\n","\n","batch_len = []\n","for batch_x, _, _ in train_dataloader:\n","    batch_len.append(batch_x.size(0))\n","plt.hist(batch_len)"]},{"cell_type":"markdown","metadata":{"id":"kR_cAYRUVbor"},"source":["# Model"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":297,"status":"ok","timestamp":1654088721188,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"9CMsOucsVbVE"},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, vocab_size, input_size, hidden_size, num_class):\n","        \"\"\"\n","        Define the model weight parameters and initialize the weights.\n","\n","        Question (b)\n","        - Complete the dimension and shape of the weights and biases.\n","        - Use the model parameters (vocab_size, input_size, hidden_size, num_class).\n","        \"\"\"\n","        super(RNN, self).__init__()\n","\n","        ### COMPLETE HERE ###\n","\n","        whh_size = (hidden_size, hidden_size)\n","        wxh_size = (hidden_size, input_size)\n","        why_size = (num_class, hidden_size)\n","        bhh_size = (hidden_size, 1)\n","        bxh_size = (hidden_size, 1)\n","        bhy_size = (num_class, 1)\n","\n","        ### COMPLETE HERE ###\n","\n","        kwargs = {'device': DEVICE, 'dtype': torch.float}\n","        self.hidden = hidden_size\n","        self.num_class = num_class\n","        self.embedding = nn.Embedding(vocab_size, input_size)\n","        self.W_hh = nn.parameter.Parameter(torch.empty(whh_size, **kwargs))\n","        self.W_xh = nn.parameter.Parameter(torch.empty(wxh_size, **kwargs))\n","        self.W_hy = nn.parameter.Parameter(torch.empty(why_size, **kwargs))\n","        self.b_hh = nn.parameter.Parameter(torch.empty(bhh_size, **kwargs))\n","        self.b_xh = nn.parameter.Parameter(torch.empty(bxh_size, **kwargs))\n","        self.b_hy = nn.parameter.Parameter(torch.empty(bhy_size, **kwargs))\n","\n","        self.init_parameters()\n","\n","    def init_parameters(self):\n","        \"\"\"\n","        Initialize the parameters with Kaiming uniform initialization.\n","\n","        Do NOT modify this method.\n","        \"\"\"\n","        nn.init.kaiming_uniform_(self.W_hh, a=math.sqrt(5))\n","        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W_hh)\n","        bound = 1 / math.sqrt(fan_in)\n","        nn.init.uniform_(self.b_hh, -bound, bound)\n","        nn.init.kaiming_uniform_(self.W_xh, a=math.sqrt(5))\n","        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W_xh)\n","        bound = 1 / math.sqrt(fan_in)\n","        nn.init.uniform_(self.b_xh, -bound, bound)\n","        nn.init.kaiming_uniform_(self.W_hy, a=math.sqrt(5))\n","        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W_hy)\n","        bound = 1 / math.sqrt(fan_in)\n","        nn.init.uniform_(self.b_hy, -bound, bound)\n","\n","    def forward(self, inputs, length):\n","        \"\"\"\n","        Question (c)\n","        - Passes a sequence of tokens into the recurrent network.\n","        - Randomly initialize h_0 with appropriate shape.\n","        - We do not want to use a hidden cell of a zero-padded token for classification!\n","        - Index the hidden state of the last valid token (excluding the zero-padding)\n","          based on the token length of each example in the batch.\n","\n","        Inputs\n","        - a batch of encoded token sequences with shape (SEQ_LEN, BATCH_SIZE)\n","        - a batch of token lengths with shape (BATCH_SIZE)\n","        Returns\n","        - Softmax probabilites for each class with shape (BATCH_SIZE, NUM_CLASS)\n","        \"\"\"\n","        \n","        ### COMPLETE HERE ###\n","\n","        BATCH_SIZE = len(length)\n","        SEQ_LEN = len(inputs)\n","        h = {}\n","        # convert to embedding vector\n","        x = self.embedding(inputs) # dim = (SEQ_LEN, BATCH_SIZE, input_size)\n","        # masking zero-padded token\n","        for i in range(BATCH_SIZE):\n","          if length[i] < SEQ_LEN:\n","            x[length[i]:,i,:] = 0\n","        # initialize first hidden state\n","        h[0] = torch.zeros((self.hidden, BATCH_SIZE)).to(DEVICE) # dim = (hidden_size, BATCH_SIZE)\n","        for t in range(SEQ_LEN): # loop SEQ_LEN times\n","          h[t+1] = torch.tanh(torch.matmul(self.W_hh, h[t]) + torch.matmul(self.W_xh, x[t,:,:].T) + self.b_xh + self.b_hh)\n","        softmax = nn.Softmax(dim=0)\n","        \n","        final_h = torch.zeros((self.hidden, BATCH_SIZE)).to(DEVICE)\n","        for i in range(BATCH_SIZE):\n","          final_h[:,i] = h[length[i].item()-1][:,i]\n","        softmax_probs = softmax(torch.matmul(self.W_hy, final_h) + self.b_hy).T\n","        \n","        ### COMPLETE HERE ###\n","\n","        return softmax_probs\n","    \n","    def compute_loss(self, prediction, label):\n","        \"\"\"\n","        Question (d)\n","        - Compute the cross entropy loss and the number of correct predictions\n","        - Do NOT use loss function in torch.nn library ex) nn.CrossEntropyLoss()\n","        - Hint: use torch.nn.functional.one_hot(tensor, num_classes=?) to generate one-hot encodings\n","\n","\n","        Inputs\n","        - prediction: output from self.forward(inputs) with shape (BATCH_SIZE, NUM_CLASS)\n","        - label: integer labels of the batch inputs with shape (BATCH_SIZE)\n","        Returns\n","        - cross entropy loss of the batch (float) and number of correct predictions (integer)\n","        \"\"\"\n","        loss = 0\n","        correct = 0\n","\n","        ### COMPLETE HERE ###\n","\n","        correct_answer = torch.nn.functional.one_hot(label, num_classes=self.num_class).float()\n","        loss = -(1/prediction.size(0)) * torch.sum(correct_answer * torch.log(prediction))\n","        correct = (prediction.argmax(1) == label).sum().item()\n","\n","        ### COMPLETE HERE ###\n","\n","        return loss, correct"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654071866682,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"cw8rYL2zB6Mi","outputId":"c7511070-8010-4838-c93a-816dbfb187bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n","torch.Size([2, 4, 3])\n","torch.Size([2, 4])\n","tensor([[[-0.1847,  0.6412,  0.0965],\n","         [-0.1847,  0.6412,  0.0965],\n","         [-0.1847,  0.6412,  0.0965],\n","         [ 1.1741,  0.0498, -0.1434]],\n","\n","        [[ 0.0000,  0.0000,  0.0000],\n","         [ 1.1741,  0.0498, -0.1434],\n","         [-0.1847,  0.6412,  0.0965],\n","         [-0.1847,  0.6412,  0.0965]]], grad_fn=<CopySlices>)\n"]},{"data":{"text/plain":["tensor([True, True])"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["embedding = nn.Embedding(10, 3)\n","input = torch.LongTensor([[0,0,0,1],[0,1,0,0]])\n","input2 = torch.LongTensor([[0,0,0,1],[0,1,0,0]])\n","print(torch.where(input == input2, input, 0).sum().item())\n","x = embedding(input)\n","print(x.shape)\n","print(input.shape)\n","# print(x)\n","x[1,0,:] = 0\n","print(x)\n","# x[0,:,:].T\n","# np.array([[1,2],[3,4]]) + np.array([[1],[2]])\n","softmax = nn.Softmax(dim=0)\n","softmax(x)\n","torch.sum(x)\n","# input.argmax(1)\n","input.max(1, keepdim = True)[1]\n","prediction = torch.LongTensor([[0,0,1.1,1],[0,1,0,0]])\n","label = torch.LongTensor([2,1])\n","prediction.argmax(1) == label"]},{"cell_type":"code","source":["a = {}\n","a[0] = torch.LongTensor([[0,0,0,1],[0,1,0,0]])\n","a[1] = torch.LongTensor([[0,0,0,0],[0,1,1,0]])\n","a[2] = torch.LongTensor([[1,0,0,0],[0,1,1,1]])\n","a[3] = torch.LongTensor([[1,1,0,0],[1,1,1,1]])\n","\n","len = torch.LongTensor([1,3])\n","\n","a[len[0].item()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbKKgu8_UIHM","executionInfo":{"status":"ok","timestamp":1654087909195,"user_tz":-540,"elapsed":7,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"b976fe08-d9e0-4851-8773-0b66f5f0d531"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 0, 0, 0],\n","        [0, 1, 1, 0]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"zIdypCAFscfV"},"source":["# Training Modules"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":371,"status":"ok","timestamp":1654088739626,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"o9lUSQJjsfrQ"},"outputs":[],"source":["class ScheduledOptim():\n","    \"\"\"\n","    Learning rate scheduler.\n","\n","    Do NOT modify.\n","    \"\"\"\n","\n","    def __init__(self, optimizer, n_warmup_steps, decay_rate):\n","        self._optimizer = optimizer\n","        self.n_warmup_steps = n_warmup_steps\n","        self.decay = decay_rate\n","        self.n_steps = 0\n","        self.initial_lr = optimizer.param_groups[0]['lr']\n","        self.current_lr = optimizer.param_groups[0]['lr']\n","\n","    def zero_grad(self):\n","        self._optimizer.zero_grad()\n","    \n","    def step(self):\n","        self._optimizer.step()\n","    \n","    def get_lr(self):\n","        return self.current_lr\n","    \n","    def update(self):\n","        if self.n_steps < self.n_warmup_steps:\n","            lr = self.n_steps / self.n_warmup_steps * self.initial_lr\n","        elif self.n_steps == self.n_warmup_steps:\n","            lr = self.initial_lr\n","        else:\n","            lr = self.current_lr * self.decay\n","        \n","        self.current_lr = lr\n","        for param_group in self._optimizer.param_groups:\n","            param_group['lr'] = lr\n","\n","        self.n_steps += 1"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654088741149,"user":{"displayName":"전현성","userId":"03887945282849978477"},"user_tz":-540},"id":"pgisHLbUsLkM"},"outputs":[],"source":["\"\"\"\n","Functions for training and evaluating the model.\n","\n","Question (e)\n","- There has been minor changes with the model forward operation and loss computation.\n","  Compare the updates with the train, evaluate functions that we have previously used,\n","  and complete the train and evaluate function that works for the current model architecture.\n","- Use the methods of the scheduler to perform necessary operations on the optimizer.\n","- Do NOT change the arguments given to the train, evaluate functions.\n","\"\"\"\n","\n","def train(model, train_loader, scheduler):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    \n","    ### COMPLETE HERE ###\n","\n","    tqdm_bar = tqdm(train_loader)\n","\n","    for text, label, length in tqdm_bar:\n","        text = text.to(DEVICE)\n","        label = label.to(DEVICE)\n","        length = length.to(DEVICE)\n","        scheduler.zero_grad()\n","\n","        prediction = model(text, length)\n","        loss, batch_correct = model.compute_loss(prediction, label)\n","        loss.backward()\n","        train_loss += loss.item()\n","        correct += batch_correct\n","        scheduler.step()\n","        tqdm_bar.set_description(\"Epoch {} - train loss: {:.6f}\".format(epoch, loss.item()))\n","\n","    scheduler.update()\n","    train_loss /= len(train_loader.dataset)\n","    train_acc = 100. * correct / len(train_loader.dataset)\n","\n","    ### COMPLETE HERE ###\n","    \n","    return train_loss, train_acc\n","\n","def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    ### COMPLETE HERE ###\n","    \n","    with torch.no_grad():\n","        for text, label, length in tqdm(test_loader):\n","            text = text.to(DEVICE)\n","            label = label.to(DEVICE)\n","            length = length.to(DEVICE)\n","            prediction = model(text, length)\n","            loss, batch_correct = model.compute_loss(prediction, label)\n","            test_loss += loss.item()\n","            correct += batch_correct\n","    \n","    test_loss /= len(test_loader.dataset)\n","    test_acc = 100. * correct / len(test_loader.dataset)\n","\n","    ### COMPLETE HERE ###\n","\n","    return test_loss, test_acc"]},{"cell_type":"markdown","metadata":{"id":"a1qXY-CDNIia"},"source":["# Model Training"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"EA061dLNNKg2","executionInfo":{"status":"error","timestamp":1654088914277,"user_tz":-540,"elapsed":320,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"c351f1cf-10a8-43ac-f335-15e5c955c842"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-f3b9cf0bb074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"]}],"source":["\"\"\"\n","Question (f)\n","- Train your RNN model and obtain the test accuracy of 70%.\n","- Select the input size, hidden size of your choice\n","- Try various optimizer type, learning rate and scheduler options for the best performance.\n","\"\"\"\n","\n","### COMPLETE HERE ###\n","LR = 0.05\n","EPOCHS = 15\n","vocab_size = len(encoder)\n","input_size = 64\n","hidden_size = 128\n","num_class = len(set([label for (label, text) in train_data])) # 4\n","\n","model = RNN(vocab_size, input_size, hidden_size, num_class).to(DEVICE)\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","scheduler = ScheduledOptim(optimizer, n_warmup_steps=3, decay_rate=0.5)\n","scheduler.update()\n","### COMPLETE HERE ###\n","for epoch in range(1, EPOCHS + 1):\n","    lr = scheduler.get_lr()\n","    loss_train, accu_train = train(model, train_dataloader, scheduler)\n","    loss_val, accu_val = evaluate(model, valid_dataloader)\n","    print('-' * 83)\n","    print('| end of epoch {:2d} | lr: {:5.4f} | train accuracy: {:8.3f} | '\n","          'valid accuracy {:8.3f} '.format(epoch, lr, accu_train, accu_val))\n","    print('-' * 83)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UuRKsi7k41U"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"hw4_rnn (1).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}