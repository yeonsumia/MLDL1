{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2c83b8",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5785918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.0-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in /Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b679cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1452, 251) (1452,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array(pd.read_csv(\"OnlineAd_X_train.csv\", header=None))\n",
    "Y_train = pd.read_csv(\"OnlineAd_Y_train.csv\", header=None)\n",
    "Y_train = np.where(Y_train == 1)[1]\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562519c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Class=0 (no click) : 822/1452 (56.6%)\n",
      "> Class=1 (click A) : 277/1452 (19.1%)\n",
      "> Class=2 (click B) : 353/1452 (24.3%)\n"
     ]
    }
   ],
   "source": [
    "from numpy import unique\n",
    "# summarize data set\n",
    "classes = unique(Y_train)\n",
    "total = len(Y_train)\n",
    "for c in classes:\n",
    "    n_examples = len(Y_train[Y_train==c])\n",
    "    percent = n_examples / total * 100\n",
    "    print('> Class=%s : %d/%d (%.1f%%)' % (\"0 (no click)\" if c == 0 else \"1 (click A)\" if c == 1 else \"2 (click B)\", n_examples, total, percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da64af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common function\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def shuffle_set(X_train, Y_train):\n",
    "    train_set = list(zip(X_train, Y_train))\n",
    "    rd.shuffle(train_set)\n",
    "    \n",
    "    X_train, Y_train = zip(*train_set)\n",
    "    return X_train, Y_train\n",
    "\n",
    "def k_fold_estimate(k, X_train, Y_train, val_estimators):\n",
    "    indices = np.array(range(len(X_train)))\n",
    "    k_indices = np.split(indices,k)\n",
    "\n",
    "    k_x_groups = [np.array(X_train)[k_indices[i]] for i in range(k)]\n",
    "    k_y_groups = [np.array(Y_train)[k_indices[i]] for i in range(k)]\n",
    "    val_scores = []\n",
    "    for i in range(k):\n",
    "        x_val = k_x_groups[i]\n",
    "        y_val = k_y_groups[i]\n",
    "        x_train = np.concatenate(k_x_groups[:i] + k_x_groups[i+1:])\n",
    "        y_train = np.concatenate(k_y_groups[:i] + k_y_groups[i+1:])\n",
    "        val_scores.append(val_estimators[i].score(X_train, Y_train))\n",
    "    val_scores = np.array(val_scores)\n",
    "    print(\"cross-validation mean accuracy:\", np.mean(val_scores))\n",
    "    print(\"cross-validation accuracies:\", val_scores)\n",
    "    return val_estimators[np.argmax(val_scores)]\n",
    "    \n",
    "def k_fold_cv(model, k, X_train, Y_train):\n",
    "    X_train, Y_train = shuffle_set(X_train, Y_train)\n",
    "    myscore = make_scorer(roc_auc_score, multi_class='ovo', needs_proba=True)\n",
    "    cv_result = cross_validate(model, X_train, Y_train, cv=k, scoring=myscore, return_train_score=True, return_estimator=True)\n",
    "\n",
    "    val_scores = cv_result['test_score']\n",
    "    val_estimators = cv_result['estimator']\n",
    "    train_scores = cv_result['train_score']\n",
    "    \n",
    "    return val_scores, train_scores, val_estimators, X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b945d0",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9155f",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa35009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def k_fold_cv_kNN(k, X_train, Y_train):\n",
    "    mknn = KNeighborsClassifier()\n",
    "    return k_fold_cv(mknn, k, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "692f11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.6423789028094739\n",
      "cross-validation scores: [0.65314276 0.62302009 0.66291887 0.62454817 0.6205619  0.67008164]\n",
      "training set scores: [0.83898975 0.83928588 0.83092452 0.84467956 0.83536103 0.83296642]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "val_scores, train_scores, val_estimators, _, _ =  k_fold_cv_kNN(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39076803",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1b9fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def k_fold_cv_LR(k, X_train, Y_train):\n",
    "    mlgr = LogisticRegression(max_iter=200)\n",
    "    return k_fold_cv(mlgr, k, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5753c50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.6791401647147784\n",
      "cross-validation scores: [0.67737637 0.63186559 0.67640261 0.71753519 0.65977127 0.71188996]\n",
      "training set scores: [0.91525182 0.91991391 0.91159579 0.90340909 0.90876782 0.90199859]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "val_scores, train_scores, val_estimators, X_train, Y_train = k_fold_cv_LR(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda5fa46",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2e1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def k_fold_cv_LDA(k, X_train, Y_train):\n",
    "    mlda = LinearDiscriminantAnalysis()\n",
    "    return k_fold_cv(mlda, k, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "210c4490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.6813732666948442\n",
      "cross-validation scores: [0.69257604 0.63156392 0.70317557 0.7060318  0.65547347 0.6994188 ]\n",
      "training set scores: [0.87222586 0.8805675  0.87740323 0.86553583 0.87927121 0.87526377]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "val_scores, train_scores, val_estimators, _, _ =  k_fold_cv_LDA(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c79f0",
   "metadata": {},
   "source": [
    "### Quadratic Discirminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ac1e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def k_fold_cv_QDA(k, X_train, Y_train):\n",
    "    mqda = QuadraticDiscriminantAnalysis()\n",
    "    return k_fold_cv(mqda, k, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77fc398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.5363932942467762\n",
      "cross-validation scores: [0.55250936 0.54957466 0.50274731 0.55689791 0.51873789 0.53789264]\n",
      "training set scores: [0.98921983 0.98945164 0.98897458 0.98752834 0.98923203 0.98985302]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeonhyeonseong/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2212)\n",
    "k = 6\n",
    "\n",
    "val_scores, train_scores, val_estimators, _, _ =  k_fold_cv_QDA(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdadd4e",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5508a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def k_fold_cv_NB(k, X_train, Y_train):\n",
    "    mnb = GaussianNB()\n",
    "    return k_fold_cv(mnb, k, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c87877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.7004772169051768\n",
      "cross-validation scores: [0.73460441 0.67261962 0.73705572 0.68563607 0.68019995 0.69274753]\n",
      "training set scores: [0.71053553 0.72244853 0.71242088 0.71922231 0.7180289  0.72011451]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "val_scores, train_scores, val_estimators, _, _ =  k_fold_cv_NB(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe3e4a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ae2db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def k_fold_tune_RF(k, X_train, Y_train):\n",
    "    mrf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    params = { \n",
    "        'max_depth': [2, 4, 6],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'n_estimators': [100, 150, 200],\n",
    "        'max_features': ['auto', 'sqrt']\n",
    "    }\n",
    "    scorer = make_scorer(roc_auc_score, multi_class='ovo', needs_proba=True)\n",
    "    grid_cv = GridSearchCV(estimator=mrf, param_grid=params, scoring=scorer, cv=k, refit=True)\n",
    "    grid_result = grid_cv.fit(X_train, Y_train)\n",
    "\n",
    "    return grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73016216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 4\n",
      "max_features: auto\n",
      "min_samples_leaf: 2\n",
      "min_samples_split: 10\n",
      "n_estimators: 150\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "cv_params = k_fold_tune_RF(k, X_train, Y_train)\n",
    "for key, value in cv_params.items():\n",
    "    print(key+\":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24db8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_RF(k, X_train, Y_train):\n",
    "    mrf = RandomForestClassifier(\n",
    "        max_depth=4,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=2,\n",
    "        n_estimators=150,\n",
    "        max_features='auto'\n",
    "    )\n",
    "    return k_fold_cv(mrf, k, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cb1351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.725969363416875\n",
      "cross-validation scores: [0.74947652 0.70348127 0.76488542 0.70693009 0.69379598 0.7372469 ]\n",
      "training set scores: [0.84567213 0.85251449 0.85297625 0.85306436 0.84894587 0.85509123]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "val_scores, train_scores, val_estimators, X_train, Y_train =  k_fold_cv_RF(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806bca1",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83387eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def k_fold_cv_Boost(k, X_train, Y_train):\n",
    "    n_estimators = np.array([60, 65, 70, 75, 80])\n",
    "    best_score = 0\n",
    "    best_learning_rate = 0\n",
    "    best_n_estimator = 0\n",
    "    for n_estimator in n_estimators:\n",
    "        learning_rate = 10 / n_estimator\n",
    "        mabc = GradientBoostingClassifier(n_estimators=n_estimator, learning_rate=learning_rate)\n",
    "        val_scores, train_scores, val_estimators, X_train, Y_train = k_fold_cv(mabc, k, X_train, Y_train)\n",
    "        if(best_score < np.mean(val_scores)):\n",
    "            best_score = np.mean(val_scores)\n",
    "            best_val_scores = val_scores\n",
    "            best_train_scores = train_scores\n",
    "            best_estimators = val_estimators\n",
    "            best_n_estimator = n_estimator\n",
    "            best_learning_rate = learning_rate\n",
    "            best_X_train = X_train\n",
    "            best_Y_train = Y_train\n",
    "    return best_val_scores, best_train_scores, best_estimators, best_n_estimator, best_learning_rate, best_X_train, best_Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a6d3aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.7239251429836396\n",
      "cross-validation scores: [0.73972452 0.74590032 0.65446805 0.75894031 0.75185619 0.69266146]\n",
      "training set scores: [0.99779862 0.99874736 0.99808552 0.99877111 0.99711683 0.9988365 ]\n",
      "n_estimator: 65\n",
      "learning rate: 0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "rd.seed(2022)\n",
    "k = 6\n",
    "val_scores, train_scores, val_estimators, n_estimator, learning_rate, X_train, Y_train  =  k_fold_cv_Boost(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)\n",
    "print(\"n_estimator:\", n_estimator)\n",
    "print(\"learning rate:\", learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d331a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def k_fold_tune_XGB1(k, X_train, Y_train):\n",
    "    param_test1 = {\n",
    "     'max_depth': [3, 6, 9],\n",
    "     'min_child_weight': [1, 3, 5]\n",
    "    }\n",
    "    mxgb = XGBClassifier(\n",
    "        learning_rate=0.1, \n",
    "        n_estimators=1000, \n",
    "        max_depth=5, \n",
    "        min_child_weight=1, \n",
    "        gamma=0, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic', \n",
    "        nthread=-1, \n",
    "        seed=2022\n",
    "    )\n",
    "    \n",
    "    myscore = make_scorer(roc_auc_score, multi_class='ovo', needs_proba=True)\n",
    "    gsearch1 = GridSearchCV(\n",
    "        estimator = mxgb,\n",
    "        param_grid = param_test1, \n",
    "        scoring=myscore,\n",
    "        n_jobs=-1,\n",
    "        cv=6, \n",
    "        verbose=10\n",
    "    )\n",
    "    grid_result = gsearch1.fit(X_train, Y_train)\n",
    "    return grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c9f3236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 9 candidates, totalling 54 fits\n",
      "max_depth: 9\n",
      "min_child_weight: 1\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "cv_params = k_fold_tune_XGB1(k, X_train, Y_train)\n",
    "for key, value in cv_params.items():\n",
    "    print(key+\":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f80c4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_tune_XGB2(k, X_train, Y_train):\n",
    "    param_test2 = {\n",
    "     'gamma':[i/10.0 for i in range(0,5)]\n",
    "    }\n",
    "    mxgb = XGBClassifier(\n",
    "        learning_rate=0.1, \n",
    "        n_estimators=1000, \n",
    "        max_depth=9, \n",
    "        min_child_weight=1, \n",
    "        gamma=0, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic', \n",
    "        nthread=-1, \n",
    "        seed=2022\n",
    "    )\n",
    "    \n",
    "    myscore = make_scorer(roc_auc_score, multi_class='ovo', needs_proba=True)\n",
    "    gsearch2 = GridSearchCV(\n",
    "        estimator = mxgb,\n",
    "        param_grid = param_test2, \n",
    "        scoring=myscore,\n",
    "        n_jobs=-1,\n",
    "        cv=6, \n",
    "        verbose=10\n",
    "    )\n",
    "    grid_result = gsearch2.fit(X_train, Y_train)\n",
    "    return grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2e299cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 5 candidates, totalling 30 fits\n",
      "gamma: 0.3\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "cv_params = k_fold_tune_XGB2(k, X_train, Y_train)\n",
    "for key, value in cv_params.items():\n",
    "    print(key+\":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2e954c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_tune_XGB3(k, X_train, Y_train):\n",
    "    param_test3 = {\n",
    "     'subsample':[i/10.0 for i in range(6,9)],\n",
    "     'colsample_bytree':[i/10.0 for i in range(6,9)]\n",
    "    }\n",
    "\n",
    "    mxgb = XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000, \n",
    "        max_depth=9, \n",
    "        min_child_weight=1, \n",
    "        gamma=0.3, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic', \n",
    "        nthread=-1, \n",
    "        seed=2022\n",
    "    )\n",
    "    \n",
    "    myscore = make_scorer(roc_auc_score, multi_class='ovo', needs_proba=True)\n",
    "    gsearch3 = GridSearchCV(\n",
    "        estimator = mxgb,\n",
    "        param_grid = param_test3, \n",
    "        scoring=myscore,\n",
    "        n_jobs=-1,\n",
    "        cv=6, \n",
    "        verbose=10\n",
    "    )\n",
    "    grid_result = gsearch3.fit(X_train, Y_train)\n",
    "    return grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba04fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 9 candidates, totalling 54 fits\n",
      "colsample_bytree: 0.7\n",
      "subsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "\n",
    "cv_params = k_fold_tune_XGB3(k, X_train, Y_train)\n",
    "for key, value in cv_params.items():\n",
    "    print(key+\":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d783f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_XGB(k, X_train, Y_train):\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate=0.1, \n",
    "        n_estimators=1000, \n",
    "        max_depth=5, \n",
    "        min_child_weight=1, \n",
    "        gamma=0.3, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.7,\n",
    "        objective= 'binary:logistic', \n",
    "        nthread=-1, \n",
    "        seed=2022\n",
    "    )\n",
    "    return k_fold_cv(xgb, k, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528e97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.7195497544036722\n",
      "cross-validation scores: [0.72589001 0.69829325 0.73743113 0.71784359 0.69069007 0.74715049]\n",
      "training set scores: [1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "rd.seed(2022)\n",
    "k = 6\n",
    "val_scores, train_scores, val_estimators, X_train, Y_train = k_fold_cv_XGB(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1bdd6",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdfadd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean accuracy: 0.7310606060606061\n",
      "cross-validation accuracies: [0.73415978 0.73829201 0.73140496 0.7238292  0.73553719 0.7231405 ]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "# logistic classifier accuracy without regularization term\n",
    "k = 6\n",
    "k_fold_estimate(k, X_train, Y_train, val_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fd678",
   "metadata": {},
   "source": [
    "### Logistic Regression + Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27832c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def k_fold_cv_LR_Lasso(k, X_train, Y_train):\n",
    "    best_score = 0.0\n",
    "    best_c = 0\n",
    "    c_list = [rd.uniform(1e-5,1e2) for _ in range(20)]\n",
    "    for c in c_list:\n",
    "        mlgrlasso = LogisticRegression(max_iter=200, penalty='l1', solver='liblinear', C=c)\n",
    "        val_scores, train_scores, val_estimators, X_train, Y_train = k_fold_cv(mlgrlasso, k, X_train, Y_train)\n",
    "        if(best_score < np.mean(val_scores)):\n",
    "            best_score = np.mean(val_scores)\n",
    "            best_val_scores = val_scores\n",
    "            best_train_scores = train_scores\n",
    "            best_estimators = val_estimators\n",
    "            best_c = c\n",
    "            best_X_train = X_train\n",
    "            best_Y_train = Y_train\n",
    "    return best_val_scores, best_train_scores, best_estimators, best_c, best_X_train, best_Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59d61c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.66336519226951\n",
      "cross-validation scores: [0.69350731 0.68543705 0.61934737 0.65562856 0.65963321 0.66663766]\n",
      "training set scores: [0.89186569 0.89374422 0.8987719  0.9038029  0.90105394 0.89885405]\n",
      "regularization strength: 0.26317734500973883\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "rd.seed(2022)\n",
    "k = 6\n",
    "val_scores, train_scores, val_estimators, c, X_train, Y_train =  k_fold_cv_LR_Lasso(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)\n",
    "print(\"regularization strength:\", 1/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd4cb779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean accuracy: 0.7208448117539027\n",
      "cross-validation accuracies: [0.71763085 0.71969697 0.71625344 0.72520661 0.7238292  0.72245179]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "k_fold_estimate(k, X_train, Y_train, val_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdc0ec",
   "metadata": {},
   "source": [
    "### Logistic Regression + Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58f1e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def k_fold_cv_LR_Ridge(k, X_train, Y_train):\n",
    "    best_score = 0.0\n",
    "    best_c = 0\n",
    "    c_list = [rd.uniform(1e-5,1e2) for _ in range(20)]\n",
    "    for c in c_list:\n",
    "        mlgrridge = LogisticRegression(max_iter=200, penalty='l2', solver='liblinear', C=c)\n",
    "        val_scores, train_scores, val_estimators, X_train, Y_train = k_fold_cv(mlgrridge, k, X_train, Y_train)\n",
    "        if(best_score < np.mean(val_scores)):\n",
    "            best_score = np.mean(val_scores)\n",
    "            best_val_scores = val_scores\n",
    "            best_train_scores = train_scores\n",
    "            best_estimators = val_estimators\n",
    "            best_c = c\n",
    "            best_X_train = X_train\n",
    "            best_Y_train = Y_train\n",
    "    return best_val_scores, best_train_scores, best_estimators, best_c, best_X_train, best_Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c17063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean score: 0.6643869387299887\n",
      "cross-validation scores: [0.6470984  0.67496822 0.66376247 0.68504842 0.67238048 0.64306364]\n",
      "training set scores: [0.90782447 0.90012607 0.89970552 0.90079919 0.90213888 0.90873176]\n",
      "regularization strength: 0.012761200171725823\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "rd.seed(2022)\n",
    "k = 6\n",
    "val_scores, train_scores, val_estimators, c, X_train, Y_train =  k_fold_cv_LR_Ridge(k, X_train, Y_train)\n",
    "print(\"cross-validation mean score:\", np.mean(val_scores))\n",
    "print(\"cross-validation scores:\", val_scores)\n",
    "print(\"training set scores:\", train_scores)\n",
    "print(\"regularization strength:\", 1/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d067533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean accuracy: 0.7289944903581267\n",
      "cross-validation accuracies: [0.73071625 0.73140496 0.72520661 0.72727273 0.73415978 0.72520661]\n"
     ]
    }
   ],
   "source": [
    "rd.seed(2022)\n",
    "k = 6\n",
    "k_fold_estimate(k, X_train, Y_train, val_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b7045",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45eab4",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb949d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation mean accuracy: 0.9382460973370064\n",
      "cross-validation accuracies: [0.93595041 0.93801653 0.93870523 0.94077135 0.93870523 0.93732782]\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "# X\n",
    "rd.seed(2022)\n",
    "k = 6\n",
    "best_estimator = k_fold_estimate(k, X_train, Y_train, val_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5464477",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c53dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(pd.read_csv(\"OnlineAd_X_test.csv\", header=None))\n",
    "Y_predict = np.zeros((300,3)).astype('int64')\n",
    "Y_pred = best_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de3d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = best_estimator.predict(X_test)\n",
    "for i, value in enumerate(Y_pred):\n",
    "    Y_predict[i, value] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f669298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame(Y_predict)\n",
    "dataframe.to_csv(\"2021-11780_pred.csv\", header=None, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
