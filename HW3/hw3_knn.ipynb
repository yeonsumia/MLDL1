{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw3_knn.ipynb","provenance":[],"collapsed_sections":["f7MWUDI2IBYW","rR3VeoqMIFbq","jMw488CqIOhm","yvwolO5qHzXl","lZDHMwziIpja","_-IRMbqqRtmh"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f7MWUDI2IBYW"},"source":["## Colab Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsEbh_t58ZJo","executionInfo":{"status":"ok","timestamp":1631357877534,"user_tz":-540,"elapsed":20347,"user":{"displayName":"­하성수 / 학생 / 데이터사이언스학과","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12292320467331069884"}},"outputId":"c8b8b884-634b-4720-ad61-a4bcaa8feeee"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"_GXMM3Js7hII"},"source":["\"\"\"\n","Change directory to where this file is located\n","\"\"\"\n","#%cd 'COPY&PASTE FILE DIRECTORY HERE'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rR3VeoqMIFbq"},"source":["## Import Modules"]},{"cell_type":"code","metadata":{"id":"JAC2qQEy7rM8"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from mnist.data_utils import load_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jMw488CqIOhm"},"source":["## K-Nearest Neighbor Implementation"]},{"cell_type":"code","metadata":{"id":"zpsV2Bb3r3s4"},"source":["class KNN:\n","    \"\"\" k-nearest neighbor classifier class \"\"\"\n","\n","    def train(self, X, y):\n","        \"\"\"\n","        Train the classifier using the given training data (X, y).\n","        Recall that for k-nearest neighbors this is just memorizing the training data.\n","\n","        Do NOT Modify this method.\n","\n","        Inputs\n","        - X: A numpy array of shape (N, D), where N is the number of data points,\n","            D is the dimensionality of each data point.\n","        - y: A numpy array of shape (N,) containing the training labels, where\n","            y[i] is the label for X[i]. With C classes, each y[i] is an integer\n","            from 0 to C-1.\n","        \"\"\"\n","        self.X_train = X\n","        self.y_train = y\n","\n","    def inference(self, X_test, k=1, dist_metric='dot'):\n","        \"\"\"\n","        For each test example in X, this method predicts its label by majority vote\n","        from the k nearest training samples. It returns the predicted labels. \n","\n","        Do NOT Modify this method.\n","\n","        Inputs\n","        - X_test: A numpy array of shape (N, D), where N is the number of test data points,\n","            D is the dimensionality of each data point.\n","        - X_train: A numpy array of shape (M, D), where M is the number of training data points,\n","            D is the dimensionality of each data point.\n","        - k: The number of neighbors to participate in voting.\n","            dist_metric: Determines the distance metric to use. The default is dot-product ('dot'),\n","            but you will need to implement 'l2' for question (b).\n","        Returns\n","        - y_pred: A numpy array of shape (N,) containing predicted labels for the test data X,\n","            where y_pred[i] is the predicted label for the test point X[i].\n","        \"\"\"\n","        dists = self.compute_distance(X_test, dist_metric)\n","        y_pred = self.predict_labels(X_test, dists, k)\n","        return y_pred\n","\n","    def compute_distance(self, X_test, dist_metric='l2'):\n","        \"\"\"\n","        Computes the distance between the training data and test data, \n","        using dot-product similarity or Euclidean (L2) distance as the distance metric.\n","\n","        Question (a)\n","\n","        Inputs\n","        - X_test: A numpy array of shape (N, D), where N is the number of test data points,\n","            D is the dimensionality of each data point.\n","        - X_train: A numpy array of shape (M, D), where M is the number of training data points,\n","            D is the dimensionality of each data point.\n","        - dist_metric: Determines the distance metric to use.\n","        Returns\n","        - dists: A numpy array of shape (N, M) where N is the number of test data points, \n","            and M is the number of traininig data points, containing distances between \n","            each pair of test and train data points based on the given distance metric.\n","        \"\"\"\n","        if dist_metric=='dot': \n","            # your code\n","\n","        elif dist_metric=='cos':\n","            # your code\n","\n","        elif dist_metric=='l2':          \n","            # your code\n","\n","        return dists\n","\n","    def predict_labels(self, X_test, dists, k):\n","        \"\"\"\n","        For the given test image, this method takes a majority vote from k closest points\n","        to predict the class of the test image.\n","\n","        Question (b)\n","\n","        Inputs\n","        - X_test: A numpy array of shape (N, D), where N is the number of test data points,\n","            D is the dimensionality of each data point.\n","        - dists: A numpy array of shape (N, M) where N is the number of test data points, \n","            and M is the number of traininig data points, containing distances between \n","            each pair of test and train data points based on the given distance metric.\n","        - k: The number of neighbors to participate in voting.\n","        Returns\n","        - y_pred: A numpy array of shape (N,) containing predicted labels for the test data X,\n","            where y_pred[i] is the predicted label for the test point X[i].\n","        \"\"\"\n","        # your code\n","\n","        return None\n","\n","    def evaluate(self, y, y_hat):\n","        \"\"\"\n","        Compares the predicted labels to the ground truth y, and prints the\n","        classification accuracy.\n","        \n","        Do NOT Modify this method.\n","\n","        Inputs\n","        - y: A numpy array of shape (N,) containing the ground truth labels, where\n","            N is the number of test examples. With C classes, each y[i] is an integer\n","            from 0 to C-1.\n","        - y_hat: A numpy array of shape (N,) containing the predicted labels, where\n","            N is the number of test examples. With C classes, each y_pred[i] is\n","            an integer from 0 to C-1.\n","        Returns:\n","        - accuracy\n","        \"\"\"\n","        y_hat = np.expand_dims(y_hat, axis=1)\n","        num_correct = np.sum(y_hat == y)\n","        accuracy = float(num_correct) / y.shape[0]\n","        return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yvwolO5qHzXl"},"source":["## Data Loading"]},{"cell_type":"code","metadata":{"id":"zR9dOpGX_0iz"},"source":["def sample_data(X, y, count):\n","    mask = np.random.choice(X.shape[0], count, replace=False)\n","    X_sampled = X[mask]\n","    y_sampled = y[mask]\n","    return X_sampled, y_sampled"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOzrdgGSHVXF"},"source":["num_train_data = 1000\n","num_test_data = 200\n","\n","X_train_src, y_train_src, X_test_src, y_test_src = load_data(one_hot_encoding=False) # Training data is flattened when it is loaded\n","X_train, y_train = sample_data(X_train_src, y_train_src, num_train_data)\n","X_test, y_test = sample_data(X_test_src, y_test_src, num_test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZDHMwziIpja"},"source":["## Model Training & Evaluation"]},{"cell_type":"code","metadata":{"id":"nfq-3_r4IsHB"},"source":["model = KNN()\n","model.train(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPmKakDuuc8b"},"source":["\"\"\"\n","Model usage for test.\n","\"\"\"\n","K = 15\n","y_pred = model.inference(X_test, k=K, dist_metric='l2')\n","acc = model.evaluate(y_test, y_pred)\n","print(\"Accuarcy:\", acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-IRMbqqRtmh"},"source":["## Experiments"]},{"cell_type":"code","metadata":{"id":"r0IsD2pwgFxM"},"source":["# Modify the number of k's and metrics to try as you want\n","num_ks = 50\n","metrics = ['dot', 'cos', 'l2']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"68AnUY2wSkMX"},"source":["# Run experiments\n","print_k_interval = 5\n","result = dict(zip(metrics, [[] for _ in range(len(metrics))]))\n","for metric in metrics:\n","    print(\"running KNN with {} distance metric\".format(metric))\n","    for k in range(1, num_ks+1):\n","        if k % print_k_interval==0:\n","            print(\"    processing... k={:3d}\".format(k))\n","        y_pred = model.inference(X_test, k=k, dist_metric=metric)\n","        acc = model.evaluate(y_test, y_pred)\n","        result[metric].append(acc)\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q47KrG6ch6MH"},"source":["# Visualize the result\n","fig = plt.figure(figsize=(10,5))\n","ax = fig.add_subplot(1,1,1)\n","\n","x_axis = np.arange(1, num_ks+1, 1)\n","for i, metric in enumerate(metrics):\n","    ax.scatter(x_axis, result[metric], label = metric)\n","\n","ax.set(title=\"K-Nearest Neighbor Accuracies on different Ks\")\n","ax.set(xlabel='K', ylabel='Accuracy')\n","ax.set(xticks=np.arange(0, num_ks+1,5), yticks=np.arange(0.5,1.0,0.05))\n","ax.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dbMIK5-WP3b"},"source":["### \n","# Question (c)\n","# Briefly report what you observe in the plot above.\n","###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zsm-h6GXW0dc"},"source":["      Write your answer to (c) in this cell."]}]}