{"cells":[{"cell_type":"markdown","metadata":{"id":"EDxtMC2g66gQ"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vj2CXov7JJqq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655348516875,"user_tz":-540,"elapsed":14732,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"49f34c3e-3898-45a6-ce0c-479599f1f97a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"DcKp4bZiJwut","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655348517345,"user_tz":-540,"elapsed":473,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"693e5deb-feed-4143-80c9-29f223dae936"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/study/Github/MLDL1/HW4\n"]}],"source":["%cd /content/drive/MyDrive/study/Github/MLDL1/HW4"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UHKo6dP6eEO6","executionInfo":{"status":"ok","timestamp":1655348520970,"user_tz":-540,"elapsed":3628,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"outputs":[],"source":["import math\n","import random\n","from pathlib import Path\n","import sys\n","sys.path.insert(0,str(Path().absolute().joinpath(\"data\")))\n","\n","from data import prepareData\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","########### import yours ###########\n","\n","####################################\n","\n","BATCH_SIZE = 64\n","\n","# TRAIN_RATIO: train dataset ratio, should be a float in (0, 0.8]\n","# (0.8-TRAIN_RATIO) will be used for valid dataset\n","TRAIN_RATIO = 0.6 "]},{"cell_type":"markdown","source":["## Util"],"metadata":{"id":"Kz2VM-9MIyKe"}},{"cell_type":"markdown","source":["**Do NOT Modify** code blocks in this section"],"metadata":{"id":"8qCY42PE0kRj"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"OOnSsL1EeG85","executionInfo":{"status":"ok","timestamp":1655348520970,"user_tz":-540,"elapsed":7,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"outputs":[],"source":["SEED = 1234\n","\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","random.seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","source":["def train(model, iterator, optimizer, loss_fn, clip):\n","    \n","    model.train()\n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","\n","        src = batch[0].to(device)\n","        trg = batch[1].to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        output = model(src, trg)\n","        loss = loss_fn(output, trg)\n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"metadata":{"id":"UHo7XkIGIz2z","executionInfo":{"status":"ok","timestamp":1655348520971,"user_tz":-540,"elapsed":7,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, loss_fn):\n","    \n","    model.eval()\n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src = batch[0].to(device)\n","            trg = batch[1].to(device)\n","\n","            output = model(src, trg)\n","\n","            loss = loss_fn(output, trg)\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"metadata":{"id":"l2-jeXr-I1yP","executionInfo":{"status":"ok","timestamp":1655348520971,"user_tz":-540,"elapsed":6,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PgCsIyawXoN"},"source":["## Dataset & Dataloader"]},{"cell_type":"markdown","source":["**Do NOT Modify** code blocks in this section"],"metadata":{"id":"40ZOR80S0wet"}},{"cell_type":"code","source":["MAX_LENGTH = 10\n","VALID_RATIO = 0.8-TRAIN_RATIO\n","\n","SOS_token = 0\n","EOS_token = 1"],"metadata":{"id":"jwwJGiyETHsL","executionInfo":{"status":"ok","timestamp":1655348520971,"user_tz":-540,"elapsed":5,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":134,"metadata":{"id":"fePBsU2GKoaI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655356751055,"user_tz":-540,"elapsed":5503,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"90bbaf89-d087-4df7-83da-734b8a70bf61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 135842 sentence pairs\n","Trimmed to 10599 sentence pairs\n","Counting words...\n","Counted words:\n","fra 4345\n","eng 2803\n","data example\n","['je suis votre medecin .', 'i m your doctor .']\n"]}],"source":["class TranslateDataset(Dataset):\n","    def __init__(self, max_length=10, fra2eng=True):\n","        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length=max_length, reverse=fra2eng)\n","        self.max_length=max_length\n","\n","        self.input_lang.addWord('PAD')\n","        self.output_lang.addWord('PAD')\n","        self.input_lang_pad = self.input_lang.word2index['PAD']\n","        self.output_lang_pad = self.output_lang.word2index['PAD']\n","        \n","        print(\"data example\")\n","        print(random.choice(self.pairs))\n","\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, idx):\n","        pair = self.pairs[idx]\n","        x, y = self._tensorsFromPair(pair)\n","        return x, y\n","\n","    def _tensorFromSentence(self, lang, sentence):\n","        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n","        indexes.append(EOS_token)\n","        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n","\n","    def _tensorsFromPair(self, pair):\n","        input_tensor = self._tensorFromSentence(self.input_lang, pair[0])\n","        target_tensor = self._tensorFromSentence(self.output_lang, pair[1])\n","        return (input_tensor, target_tensor)\n","\n","    def collate_fn(self, data):\n","        x_batch = []; y_batch = []\n","        \n","        for x, y in data:\n","            if x.shape[0] < self.max_length-1:\n","                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n","            elif x.shape[0] > self.max_length-1:\n","                x = x[:self.max_length-1]\n","            if y.shape[0] < self.max_length-1:\n","                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n","            elif y.shape[0] > self.max_length-1:\n","                y = y[:self.max_length-1]\n","\n","            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n","            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n","        \n","        return torch.stack(x_batch), torch.stack(y_batch)\n","\n","dataset = TranslateDataset(max_length=MAX_LENGTH)\n","\n","train_size = int(len(dataset)*TRAIN_RATIO)\n","valid_size = int(len(dataset)*VALID_RATIO)\n","train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n","\n","train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n","valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"8TqutY58tG-h"},"source":["# 1. Seq2Seq model with Attention Mechanism"]},{"cell_type":"markdown","metadata":{"id":"A5xyf2mHuhmX"},"source":["## Implement LSTM Seq2Seq Model"]},{"cell_type":"code","source":["class LSTMEncoder(nn.Module):\n","    \n","    def __init__(self, in_dim, emb_dim, hid_dim):\n","        super(LSTMEncoder, self).__init__()\n","\n","        self.embedding = nn.Embedding(in_dim, emb_dim, padding_idx=dataset.input_lang.n_words-1)\n","        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=1, batch_first=True)\n","\n","\n","    def forward(self, input, hidden, cell):\n","        '''\n","        Q2 - (a)\n","        Implement forward method of LSTM Encoder Module\n","\n","        INPUT\n","        - input: input sentence, (B, max_len)\n","        - hidden: initialized hidden state, (1, B, hid_dim)\n","        - cell: initialized cell state, (1, B, hid_dim)\n","\n","        OUTPUT\n","        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n","        Feel free to return outputs you need.\n","        some examples below\n","        - hidden states of encoder\n","\n","        '''\n","        ################### YOUR CODE ###################\n","\n","        embedding = self.embedding(input) # shape = (B, max_len, emb_dim)\n","        # output shape = (B, max_len, hid_dim)\n","        # hidden_state shape = (B, hid_dim)\n","        # cell_state shape = (1, B, hid_dim)\n","        outputs, (hidden_state, cell_state) = self.lstm(embedding, (hidden, cell))\n","\n","        return outputs, hidden_state[0], cell_state\n","\n","        #################################################"],"metadata":{"id":"1MM6lL95JcDa","executionInfo":{"status":"ok","timestamp":1655359588678,"user_tz":-540,"elapsed":326,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["class AttnLSTMDecoder(nn.Module):\n","\n","    def __init__(self, emb_dim, hid_dim, out_dim, dropout, enc_hiddens=None):\n","        super(AttnLSTMDecoder, self).__init__()\n","        \n","        self.t = 0 # (t)th token decoder\n","        self.enc_hiddens = enc_hiddens # encoder output\n","        self.dropout = dropout\n","        \n","        self.embedding = nn.Embedding(out_dim, emb_dim, padding_idx=dataset.output_lang.n_words-1)\n","        self.lstm = nn.LSTM(emb_dim + hid_dim, hid_dim, batch_first=True, dropout=dropout)\n","        self.classifier = nn.Linear(hid_dim, out_dim)\n","\n","\n","    def forward(self, input, hidden, cell):\n","        '''\n","        Q2 - (a)\n","        Implement forward method of LSTM Decoder Module with dot-product attention\n","\n","        INPUT\n","        - input: input words (B, 1)\n","        - hidden: previous hidden state (B, hid_dim)\n","        - cell: previous cell state (1, B, hid_dim)\n","\n","        OUTPUT\n","        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n","        Feel free to return outputs you need.\n","        Some examples below\n","        - predicted token embedding (B, out_dim)\n","        - current hidden state\n","        - current cell state\n","\n","        '''\n","        ################### YOUR CODE ###################\n","\n","        # set query to calculate attention\n","        query = hidden.unsqueeze(2) # shape = (B, hid_dim, 1)\n","        keys = self.enc_hiddens # shape = (B, max_len, hid_dim)\n","        values = self.enc_hiddens.transpose(1,2) # shape = (B, hid_dim, max_len)\n","\n","        softmax = nn.Softmax(dim=1)\n","\n","        attention_coefficients = softmax(torch.bmm(keys, query)) # shape = (B, max_len, 1)\n","        \n","        attention_values = torch.bmm(values, attention_coefficients) # shape = (B, hid_dim, 1)\n","\n","        attention_values = attention_values.transpose(1,2) # shape = (B, 1, hid_dim)\n","\n","        embedding = self.embedding(input) # shape = (B, 1, emb_dim)\n","\n","        attention_embedding = nn.Dropout(self.dropout)(torch.cat((embedding, attention_values), 2)) # shape = (B, 1, emb_dim+hid_dim)\n","\n","        # output shape = (B, 1, hid_dim)\n","        # hidden_state shape = (1, B, hid_dim)\n","        # cell_state shape = (1, B, hid_dim)\n","        outputs, (curr_hidden, curr_cell) = self.lstm(attention_embedding, (hidden.unsqueeze(0), cell))\n","        outputs = outputs.transpose(0,1)\n","\n","        log_softmax = nn.LogSoftmax(dim=1)\n","\n","        predicted_embedding = log_softmax(self.classifier(outputs[0])) # shape = (B, out_dim)\n","\n","        self.t += 1 # update time for each forward\n","\n","        return predicted_embedding, curr_hidden[0], curr_cell\n","\n","        #################################################\n"],"metadata":{"id":"VPQnZdz5KKnN","executionInfo":{"status":"ok","timestamp":1655360938646,"user_tz":-540,"elapsed":306,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["class LSTMSeq2Seq(nn.Module):\n","    def __init__(self, in_dim, out_dim, emb_dim, hid_dim, device, dropout):\n","        super(LSTMSeq2Seq, self).__init__()\n","\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.emb_dim = emb_dim\n","        self.hid_dim = hid_dim\n","        self.device = device\n","        self.dropout = dropout\n","        \n","        self.encoder = LSTMEncoder(in_dim, emb_dim, hid_dim)\n","        self.decoder = AttnLSTMDecoder(emb_dim, hid_dim, out_dim, dropout)\n","        \n","    def forward(self, src, trg):\n","        '''\n","        Q2 - (b)\n","        Implement forward method of LSTM Seq2Seq Module\n","        (Decoder module should attend encoder's outputs using dot product.)\n","        \n","        INPUT\n","        - src: source language batched data (B, max_len)\n","        - trg: target language batched data (B, max_len)\n","\n","        OUTPUT\n","        - output of token prediction (B, out_dim, max_len)\n","\n","        '''\n","        batch_size, mx_len = src.shape\n","        ################### YOUR CODE ###################\n","\n","        # Encoder (start from zero-hidden & zero-cell states)\n","        init_hidden_state = init_cell_state = torch.zeros(1, batch_size, self.hid_dim).to(self.device)\n","        enc_outputs, hidden_state, cell_state = self.encoder(src, init_hidden_state, init_cell_state)\n","        \n","        # Decoder\n","        self.decoder.enc_hiddens = enc_outputs # set encoder's hidden states\n","        outputs = torch.zeros(mx_len, batch_size, dataset.output_lang.n_words).to(self.device) # to store each decoder's output\n","        \n","        x = trg[:,[0]].to(self.device)\n","\n","        for t in range(1, mx_len): # for each t'th token, get decoder outputs\n","            output, hidden_state, cell_state = self.decoder(x, hidden_state, cell_state)\n","            outputs[t] = output\n","            x = trg[:,[t]].to(self.device)\n","        \n","        self.decoder.t=0 # after for loop, reset decoder's time to evaluate properly\n","\n","        outputs = torch.permute(outputs, (1, 2, 0))\n","\n","        return outputs\n","        \n","        ################### YOUR CODE ###################"],"metadata":{"id":"zJsJ3p2NLD6c","executionInfo":{"status":"ok","timestamp":1655366558333,"user_tz":-540,"elapsed":345,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":195,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cu3WP3mYw3NV"},"source":["## Training"]},{"cell_type":"code","source":["'''\n","Q2 - (c)\n","Train your Seq2Seq model and plot losses and perplexities.\n","Upon successful training, the test perplexity should be less than 5.\n","You may use visualization libraries for plotting and modify training options such as hyperparameters and optimizer.\n","\n","'''"],"metadata":{"id":"B4YKhRe9d9qC","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"5c1830ed-6900-4700-ee83-54e51de6b2fe","executionInfo":{"status":"ok","timestamp":1655355643990,"user_tz":-540,"elapsed":6,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nQ2 - (c)\\nTrain your Seq2Seq model and plot losses and perplexities.\\nUpon successful training, the test perplexity should be less than 5.\\nYou may use visualization libraries for plotting and modify training options such as hyperparameters and optimizer.\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["def plot_history(history):\n","    plt.figure(figsize=(3 * 13, 4))\n","    plt.subplot(1, 5, 1)\n","    plt.title(\"Training and Validation Loss\")\n","    plt.plot(history['train_loss'], label=\"train_loss\")\n","    plt.plot(history['val_loss'], label=\"val_loss\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.subplot(1, 5, 2)\n","    plt.title(\"Training and Validation PPL\")\n","    plt.plot(history['train_ppl'], label=\"train_ppl\")\n","    plt.plot(history['val_ppl'], label=\"val_ppl\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"PPL\")\n","    plt.legend()\n","    plt.show()"],"metadata":{"id":"AA1G_05IW4p0","executionInfo":{"status":"ok","timestamp":1655363828656,"user_tz":-540,"elapsed":527,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":156,"outputs":[]},{"cell_type":"code","execution_count":253,"metadata":{"id":"1QQgN03XecUV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655368558458,"user_tz":-540,"elapsed":349,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"07628368-2b88-47fe-948d-6bccc6d92d5c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}],"source":["in_dim = dataset.input_lang.n_words\n","out_dim = dataset.output_lang.n_words\n","hid_dim = 256\n","emb_dim = 256\n","dropout = 0.1\n","learning_rate=2.5e-4\n","N_EPOCHS = 50\n","valid_every=5\n","best_valid_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss_fn = nn.NLLLoss(ignore_index = dataset.output_lang_pad)"]},{"cell_type":"code","execution_count":254,"metadata":{"id":"JbSR6BZKf-6L","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1655368708320,"user_tz":-540,"elapsed":148574,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"ee5d14bd-84f1-4142-f176-335ae8620e8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["hyperparameters:\n","  hid_dim: 256\n","  emb_dim: 256\n","  dropout: 0.1\n","  learning rate: 0.00025\n","  n_epochs: 50\n","==========================\n","Epoch: 01\n","\tTrain Loss: 4.189 | Train PPL:  65.927\n","==========================\n","\t Val. Loss: 2.918 |  Val. PPL:  18.512\n","Epoch: 02\n","\tTrain Loss: 2.716 | Train PPL:  15.125\n","Epoch: 03\n","\tTrain Loss: 2.440 | Train PPL:  11.478\n","Epoch: 04\n","\tTrain Loss: 2.253 | Train PPL:   9.515\n","Epoch: 05\n","\tTrain Loss: 2.116 | Train PPL:   8.300\n","Epoch: 06\n","\tTrain Loss: 2.005 | Train PPL:   7.426\n","==========================\n","\t Val. Loss: 2.065 |  Val. PPL:   7.885\n","Epoch: 07\n","\tTrain Loss: 1.909 | Train PPL:   6.747\n","Epoch: 08\n","\tTrain Loss: 1.817 | Train PPL:   6.152\n","Epoch: 09\n","\tTrain Loss: 1.737 | Train PPL:   5.680\n","Epoch: 10\n","\tTrain Loss: 1.664 | Train PPL:   5.280\n","Epoch: 11\n","\tTrain Loss: 1.594 | Train PPL:   4.924\n","==========================\n","\t Val. Loss: 1.806 |  Val. PPL:   6.084\n","Epoch: 12\n","\tTrain Loss: 1.529 | Train PPL:   4.612\n","Epoch: 13\n","\tTrain Loss: 1.462 | Train PPL:   4.315\n","Epoch: 14\n","\tTrain Loss: 1.401 | Train PPL:   4.058\n","Epoch: 15\n","\tTrain Loss: 1.343 | Train PPL:   3.830\n","Epoch: 16\n","\tTrain Loss: 1.284 | Train PPL:   3.613\n","==========================\n","\t Val. Loss: 1.640 |  Val. PPL:   5.154\n","Epoch: 17\n","\tTrain Loss: 1.233 | Train PPL:   3.430\n","Epoch: 18\n","\tTrain Loss: 1.177 | Train PPL:   3.246\n","Epoch: 19\n","\tTrain Loss: 1.126 | Train PPL:   3.084\n","Epoch: 20\n","\tTrain Loss: 1.075 | Train PPL:   2.931\n","Epoch: 21\n","\tTrain Loss: 1.027 | Train PPL:   2.792\n","==========================\n","\t Val. Loss: 1.517 |  Val. PPL:   4.556\n","Epoch: 22\n","\tTrain Loss: 0.980 | Train PPL:   2.663\n","Epoch: 23\n","\tTrain Loss: 0.934 | Train PPL:   2.546\n","Epoch: 24\n","\tTrain Loss: 0.889 | Train PPL:   2.433\n","Epoch: 25\n","\tTrain Loss: 0.846 | Train PPL:   2.330\n","Epoch: 26\n","\tTrain Loss: 0.804 | Train PPL:   2.234\n","==========================\n","\t Val. Loss: 1.415 |  Val. PPL:   4.118\n","Epoch: 27\n","\tTrain Loss: 0.764 | Train PPL:   2.147\n","Epoch: 28\n","\tTrain Loss: 0.725 | Train PPL:   2.064\n","Epoch: 29\n","\tTrain Loss: 0.687 | Train PPL:   1.987\n","Epoch: 30\n","\tTrain Loss: 0.649 | Train PPL:   1.914\n","Epoch: 31\n","\tTrain Loss: 0.613 | Train PPL:   1.845\n","==========================\n","\t Val. Loss: 1.378 |  Val. PPL:   3.969\n","Epoch: 32\n","\tTrain Loss: 0.579 | Train PPL:   1.784\n","Epoch: 33\n","\tTrain Loss: 0.546 | Train PPL:   1.727\n","Epoch: 34\n","\tTrain Loss: 0.512 | Train PPL:   1.669\n","Epoch: 35\n","\tTrain Loss: 0.484 | Train PPL:   1.623\n","Epoch: 36\n","\tTrain Loss: 0.454 | Train PPL:   1.575\n","==========================\n","\t Val. Loss: 1.323 |  Val. PPL:   3.754\n","Epoch: 37\n","\tTrain Loss: 0.428 | Train PPL:   1.533\n","Epoch: 38\n","\tTrain Loss: 0.399 | Train PPL:   1.490\n","Epoch: 39\n","\tTrain Loss: 0.375 | Train PPL:   1.455\n","Epoch: 40\n","\tTrain Loss: 0.350 | Train PPL:   1.419\n","Epoch: 41\n","\tTrain Loss: 0.327 | Train PPL:   1.387\n","==========================\n","\t Val. Loss: 1.280 |  Val. PPL:   3.598\n","Epoch: 42\n","\tTrain Loss: 0.304 | Train PPL:   1.355\n","Epoch: 43\n","\tTrain Loss: 0.285 | Train PPL:   1.329\n","Epoch: 44\n","\tTrain Loss: 0.265 | Train PPL:   1.303\n","Epoch: 45\n","\tTrain Loss: 0.247 | Train PPL:   1.280\n","Epoch: 46\n","\tTrain Loss: 0.230 | Train PPL:   1.259\n","==========================\n","\t Val. Loss: 1.278 |  Val. PPL:   3.590\n","Epoch: 47\n","\tTrain Loss: 0.213 | Train PPL:   1.238\n","Epoch: 48\n","\tTrain Loss: 0.199 | Train PPL:   1.220\n","Epoch: 49\n","\tTrain Loss: 0.185 | Train PPL:   1.203\n","Epoch: 50\n","\tTrain Loss: 0.172 | Train PPL:   1.187\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2808x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Train your model\n","print(f'hyperparameters:\\n  hid_dim: {hid_dim}\\n  emb_dim: {emb_dim}\\n  dropout: {dropout}\\n  learning rate: {learning_rate}\\n  n_epochs: {N_EPOCHS}')\n","history = {'train_loss':[], 'train_ppl':[], 'val_loss':[], 'val_ppl':[], 'lr':[]}\n","\n","print(\"==========================\")\n","for epoch in range(N_EPOCHS):\n","    \n","    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n","    \n","    print(f'Epoch: {epoch+1:02}')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    \n","    valid_loss = evaluate(model, valid_dataloader, loss_fn)\n","\n","    if epoch%valid_every==0:\n","        print(\"==========================\")\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            model.decoder.t=0\n","            torch.save(model.state_dict(), 'lstm-attn-model.pt')\n","\n","        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","\n","    history['train_loss'].append(train_loss)\n","    history['val_loss'].append(valid_loss)\n","    history['train_ppl'].append(math.exp(train_loss))\n","    history['val_ppl'].append(math.exp(valid_loss))\n","    history['lr'].append(optimizer.param_groups[0]['lr'])\n","\n","plot_history(history)"]},{"cell_type":"code","source":["# Test your model\n","\n","loaded_model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n","loaded_model.load_state_dict(torch.load('lstm-attn-model.pt'))\n","\n","test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n","print(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')"],"metadata":{"id":"hBXKAKZo2lSS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655368922100,"user_tz":-540,"elapsed":476,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"52a00d32-72e0-4d30-c89a-8176ca6fe360"},"execution_count":258,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"stream","name":"stdout","text":["\t Test. Loss: 1.383 |  Test. PPL:   3.989\n"]}]},{"cell_type":"markdown","source":["## [Bonus] Implement GRU Seq2Seq Model"],"metadata":{"id":"FD1SYbuKOKGN"}},{"cell_type":"code","source":["'''\n","Q2 - (d)\n","Change the modules(encoder, decoder) in Seq2Seq model to GRU, and repeat (a)~(c).\n","\n","'''"],"metadata":{"id":"Ei1fgjRveS4n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GRUEncoder(nn.Module):\n","    \n","    def __init__(self, in_dim, emb_dim, hid_dim):\n","        super(GRUEncoder, self).__init__()\n","        ################### YOUR CODE ###################\n","\n","        self.embedding = nn.Embedding(in_dim, emb_dim, padding_idx=dataset.input_lang.n_words-1)\n","        self.gru = nn.GRU(input_size=emb_dim, hidden_size=hid_dim, num_layers=1, batch_first=True)\n","\n","        #################################################\n","\n","    def forward(self, input, hidden):\n","\n","        ################### YOUR CODE ###################\n","\n","        embedding = self.embedding(input) # shape = (B, max_len, emb_dim)\n","        # output shape = (B, max_len, hid_dim)\n","        # hidden_state shape = (B, hid_dim)\n","        outputs, hidden_state = self.gru(embedding, hidden)\n","\n","        return outputs, hidden_state[0]\n","        \n","        #################################################\n","\n","        "],"metadata":{"id":"2U9A9kh3OSWW","executionInfo":{"status":"ok","timestamp":1655367243568,"user_tz":-540,"elapsed":361,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":214,"outputs":[]},{"cell_type":"code","source":["class AttnGRUDecoder(nn.Module):\n","\n","    def __init__(self, emb_dim, hid_dim, out_dim, dropout, enc_hiddens=None):\n","        super(AttnGRUDecoder, self).__init__()\n","        \n","        ################### YOUR CODE ###################\n","\n","        self.t = 0 # (t)th token decoder\n","        self.enc_hiddens = enc_hiddens # encoder output\n","        self.dropout = dropout\n","        \n","        self.embedding = nn.Embedding(out_dim, emb_dim, padding_idx=dataset.output_lang.n_words-1)\n","        self.gru = nn.GRU(emb_dim + hid_dim, hid_dim, batch_first=True, dropout=dropout)\n","        self.classifier = nn.Linear(hid_dim, out_dim)\n","\n","        #################################################\n","\n","    def forward(self, input, hidden):\n","\n","        ################### YOUR CODE ###################\n","\n","        # set query to calculate attention\n","        query = hidden.unsqueeze(2) # shape = (B, hid_dim, 1)\n","        keys = self.enc_hiddens # shape = (B, max_len, hid_dim)\n","        values = self.enc_hiddens.transpose(1,2) # shape = (B, hid_dim, max_len)\n","\n","        softmax = nn.Softmax(dim=1)\n","\n","        attention_coefficients = softmax(torch.bmm(keys, query)) # shape = (B, max_len, 1)\n","        \n","        attention_values = torch.bmm(values, attention_coefficients) # shape = (B, hid_dim, 1)\n","\n","        attention_values = attention_values.transpose(1,2) # shape = (B, 1, hid_dim)\n","\n","        embedding = self.embedding(input) # shape = (B, 1, emb_dim)\n","\n","        attention_embedding = nn.Dropout(self.dropout)(torch.cat((embedding, attention_values), 2)) # shape = (B, 1, emb_dim+hid_dim)\n","\n","        # output shape = (B, 1, hid_dim)\n","        # hidden_state shape = (1, B, hid_dim)\n","        # cell_state shape = (1, B, hid_dim)\n","        outputs, curr_hidden = self.gru(attention_embedding, hidden.unsqueeze(0))\n","        outputs = outputs.transpose(0,1)\n","\n","        log_softmax = nn.LogSoftmax(dim=1)\n","\n","        predicted_embedding = log_softmax(self.classifier(outputs[0])) # shape = (B, out_dim)\n","\n","        self.t += 1 # update time for each forward\n","\n","        return predicted_embedding, curr_hidden[0]\n","\n","        #################################################\n"],"metadata":{"id":"9-IRYjI6O0xb","executionInfo":{"status":"ok","timestamp":1655367248763,"user_tz":-540,"elapsed":316,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":215,"outputs":[]},{"cell_type":"code","source":["class GRUSeq2Seq(nn.Module):\n","    def __init__(self, in_dim, out_dim, emb_dim, hid_dim, device, dropout):\n","        super(GRUSeq2Seq, self).__init__()\n","\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.emb_dim = emb_dim\n","        self.hid_dim = hid_dim\n","        self.device = device\n","        self.dropout = dropout\n","        \n","        self.encoder = GRUEncoder(in_dim, emb_dim, hid_dim)\n","        self.decoder = AttnGRUDecoder(emb_dim, hid_dim, out_dim, dropout)\n","        \n","    def forward(self, src, trg):\n","        \n","        batch_size, mx_len = src.shape\n","        ################### YOUR CODE ###################\n","        \n","        # Encoder (start from zero-hidden & zero-cell states)\n","        init_hidden_state = torch.zeros(1, batch_size, self.hid_dim).to(self.device)\n","        enc_outputs, hidden_state = self.encoder(src, init_hidden_state)\n","        \n","        # Decoder\n","        self.decoder.enc_hiddens = enc_outputs # set encoder's hidden states\n","        outputs = torch.zeros(mx_len, batch_size, dataset.output_lang.n_words).to(self.device) # to store each decoder's output\n","        \n","        x = trg[:,[0]].to(self.device)\n","\n","        for t in range(1, mx_len): # for each t'th token, get decoder outputs\n","            output, hidden_state = self.decoder(x, hidden_state)\n","            outputs[t] = output\n","            x = trg[:,[t]].to(self.device)\n","        \n","        self.decoder.t=0 # after for loop, reset decoder's time to evaluate properly\n","\n","        outputs = torch.permute(outputs, (1, 2, 0))\n","\n","        return outputs\n","        \n","        #################################################"],"metadata":{"id":"BOOj4_hhP83d","executionInfo":{"status":"ok","timestamp":1655367255108,"user_tz":-540,"elapsed":370,"user":{"displayName":"전현성","userId":"03887945282849978477"}}},"execution_count":216,"outputs":[]},{"cell_type":"code","source":["# GRU hyperparameters\n","in_dim = dataset.input_lang.n_words\n","out_dim = dataset.output_lang.n_words\n","hid_dim = 256\n","emb_dim = 256\n","dropout = 0.1\n","learning_rate=3.5e-4\n","N_EPOCHS = 50\n","valid_every=5\n","best_valid_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","gru_model = GRUSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n","\n","optimizer = torch.optim.Adam(gru_model.parameters(), lr=learning_rate)\n","loss_fn = nn.NLLLoss(ignore_index = dataset.output_lang_pad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btgLVNPUjGbp","executionInfo":{"status":"ok","timestamp":1655370828556,"user_tz":-540,"elapsed":347,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"cb9d4ef1-0d7b-49ef-97d5-1788662a61f1"},"execution_count":275,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}]},{"cell_type":"code","source":["# Train your model\n","print(f'hyperparameters:\\n  hid_dim: {hid_dim}\\n  emb_dim: {emb_dim}\\n  dropout: {dropout}\\n  learning rate: {learning_rate}\\n  n_epochs: {N_EPOCHS}')\n","history = {'train_loss':[], 'train_ppl':[], 'val_loss':[], 'val_ppl':[], 'lr':[]}\n","\n","print(\"==========================\")\n","for epoch in range(N_EPOCHS):\n","    \n","    train_loss = train(gru_model, train_dataloader, optimizer, loss_fn, 1)\n","    \n","    print(f'Epoch: {epoch+1:02}')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    \n","    valid_loss = evaluate(gru_model, valid_dataloader, loss_fn)\n","\n","    if epoch%valid_every==0:\n","        print(\"==========================\")\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            gru_model.decoder.t=0\n","            torch.save(gru_model.state_dict(), 'gru-attn-model.pt')\n","\n","        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","\n","    history['train_loss'].append(train_loss)\n","    history['val_loss'].append(valid_loss)\n","    history['train_ppl'].append(math.exp(train_loss))\n","    history['val_ppl'].append(math.exp(valid_loss))\n","    history['lr'].append(optimizer.param_groups[0]['lr'])\n","\n","plot_history(history)"],"metadata":{"id":"usq_ohj4Qqf5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d01c5897-c66c-4e3b-c358-cca7b5fd7a79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hyperparameters:\n","  hid_dim: 256\n","  emb_dim: 256\n","  dropout: 0.1\n","  learning rate: 0.00035\n","  n_epochs: 50\n","==========================\n","Epoch: 01\n","\tTrain Loss: 3.713 | Train PPL:  40.978\n","==========================\n","\t Val. Loss: 2.747 |  Val. PPL:  15.595\n","Epoch: 02\n","\tTrain Loss: 2.553 | Train PPL:  12.840\n","Epoch: 03\n","\tTrain Loss: 2.211 | Train PPL:   9.123\n","Epoch: 04\n","\tTrain Loss: 1.984 | Train PPL:   7.270\n","Epoch: 05\n","\tTrain Loss: 1.826 | Train PPL:   6.208\n","Epoch: 06\n","\tTrain Loss: 1.699 | Train PPL:   5.468\n","==========================\n","\t Val. Loss: 1.850 |  Val. PPL:   6.357\n","Epoch: 07\n","\tTrain Loss: 1.594 | Train PPL:   4.924\n","Epoch: 08\n","\tTrain Loss: 1.497 | Train PPL:   4.466\n","Epoch: 09\n","\tTrain Loss: 1.407 | Train PPL:   4.085\n","Epoch: 10\n","\tTrain Loss: 1.328 | Train PPL:   3.772\n","Epoch: 11\n","\tTrain Loss: 1.253 | Train PPL:   3.500\n","==========================\n","\t Val. Loss: 1.611 |  Val. PPL:   5.006\n"]}]},{"cell_type":"code","source":["loaded_model = GRUSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n","loaded_model.load_state_dict(torch.load('gru-attn-model.pt'))\n","\n","test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n","print(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')"],"metadata":{"id":"WrFYlXfiRCSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655370813010,"user_tz":-540,"elapsed":955,"user":{"displayName":"전현성","userId":"03887945282849978477"}},"outputId":"40a3459a-c7a5-435f-8258-e1049107e4eb"},"execution_count":274,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"stream","name":"stdout","text":["\t Test. Loss: 1.453 |  Test. PPL:   4.274\n"]}]},{"cell_type":"markdown","source":["# 2. Seq2Seq model with Transformer"],"metadata":{"id":"qAZdJqTJXVcP"}},{"cell_type":"markdown","source":["## Implement Transformer Seq2Seq Model"],"metadata":{"id":"t07UOwbpH7CZ"}},{"cell_type":"code","source":["class TransEncoder(nn.Module):\n","    def __init__(self, input_dim, hid_dim, n_layers, n_heads, ff_dim, dropout, device, max_length = MAX_LENGTH):\n","        super().__init__()\n","\n","        self.hid_dim = hid_dim\n","        self.max_length = max_length\n","\n","        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n","        \n","        encoder_layer = TransformerEncoderLayer(hid_dim, n_heads, ff_dim, dropout, batch_first=True)\n","        self.encoder = TransformerEncoder(encoder_layer, n_layers)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        self.scale = torch.sqrt(torch.tensor([hid_dim], device = device, dtype=torch.float32))\n","        \n","    def forward(self, src, pos_emb, src_mask):\n","        '''\n","        Q3 - (c)\n","        Implement forward method of TransEncoder Module\n","        (Use torch.nn.TransformerEncoder, torch.nn.TransformerEncoderLayer)\n","        \n","        INPUT\n","        - src: source language batched data (B, max_len)\n","        - pos_emb: positional embedding (max_len, hid_dim)\n","        - src_mask: padding mask tensor for source sentences (B, max_len)\n","\n","        OUTPUT\n","        What to be returned depends on your implementation of TransSeq2Seq.\n","        Feel free to return outputs you need.\n","        Some examples below,\n","\n","        - encoder output (B, max_len, hid_dim)\n","        '''\n","        batch_size, src_len = src.shape\n","        #################### YOUR CODE ####################\n","\n","        \n","        return None\n","        ###################################################"],"metadata":{"id":"Cvv3bN0qXX1I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransDecoder(nn.Module):\n","    def __init__(self, out_dim, hid_dim, n_layers, n_heads, ff_dim, dropout, device, max_length = MAX_LENGTH):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.max_length = max_length\n","        \n","        self.tok_embedding = nn.Embedding(out_dim, hid_dim)\n","        \n","        decoder_layer = TransformerDecoderLayer(hid_dim, n_heads, ff_dim, dropout, batch_first=True)\n","        self.decoder = TransformerDecoder(decoder_layer, n_layers)\n","        \n","        self.fc_out = nn.Linear(hid_dim, out_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.scale = torch.sqrt(torch.tensor([hid_dim], device = device, dtype=torch.float32))\n","        \n","    def forward(self, trg, pos_emb, enc_src, trg_mask, trg_sub_mask, src_mask):\n","        '''\n","        Q3 - (c)\n","        Implement forward method of TransDecoder Module\n","        (Use torch.nn.TransformerDecoder, torch.nn.TransformerDecoderLayer)\n","        \n","        INPUT\n","        - trg: target language batched data (B, max_len)\n","        - pos_emb: positional embedding (max_len, hid_dim)\n","        - enc_src: encoder outputs (B, max_len, hid_dim)\n","        - trg_mask: padding mask tensor for target sentences (B, max_len)\n","        - trg_sub_mask: subsequent mask for target sentences (max_len, max_len)\n","        - src_mask: padding mask tensor for source sentences (B, max_len)\n","\n","        OUTPUT\n","        What to be returned depends on your implementation of TransSeq2Seq.\n","        Feel free to return outputs you need.\n","        Some examples below,\n","\n","        - decoder output (B, max_len, out_dim)\n","        '''\n","        batch_size, trg_len = trg.shape\n","\n","        #################### YOUR CODE ####################\n","        \n","        return None\n","        ###################################################"],"metadata":{"id":"8mKifSxjIWKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransSeq2Seq(nn.Module):\n","    def __init__(self, in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout_p, device, max_length=MAX_LENGTH):\n","        super().__init__()\n","        \n","        self.device = device\n","        self.hid_dim = hid_dim\n","        self.max_length = max_length\n","\n","        self.encoder = TransEncoder(in_dim, hid_dim, n_layers[0], n_heads, ff_dim, dropout_p, device)\n","        self.decoder = TransDecoder(out_dim, hid_dim, n_layers[1], n_heads, ff_dim, dropout_p, device)\n","        \n","    def make_src_mask(self, src):\n","        '''\n","        Q3 - (b)\n","        Implement mask generating function\n","\n","        INPUT\n","        - src: batched input sentences (B, max_len)\n","\n","        OUTPUT\n","        - Boolean padding mask tensor (B, max_len)\n","        '''\n","        #################### YOUR CODE ####################\n","        \n","        return None\n","        ###################################################\n","\n","    def make_trg_mask(self, trg):\n","        '''\n","        Q3 - (b)\n","        Implement mask generating function\n","\n","        INPUT\n","        - trg: batched target sentences (B, max_len)\n","\n","        OUTPUT\n","        - A tuple of a padding mask tensor and a subsequent mask tensor ((B, max_len), (max_len, max_len))\n","        '''\n","        #################### YOUR CODE ####################\n","\n","        return None\n","        ###################################################\n","\n","    def forward(self, src, trg):\n","        '''\n","        Q3 - (c)\n","        Implement forward method of TransSeq2Seq Module\n","        \n","        INPUT\n","        - src: source language batched data (B, max_len)\n","        - trg: target language batched data (B, max_len)\n","\n","        OUTPUT\n","        - decoder output (B, out_dim, max_dim)\n","        \n","        '''\n","        #################### YOUR CODE ####################\n","\n","        return None\n","        ###################################################\n","    \n","    \n","    def get_pos_emb(self):\n","        '''\n","        Q3 - (a)\n","        Implement absolute positional embedding\n","\n","        OUTPUT\n","        - positional embedding tensor (max_len, hid_dim)\n","        '''\n","        #################### YOUR CODE ####################\n","\n","        return None\n","        ###################################################"],"metadata":{"id":"L5VFP1-3IXmv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"KqnvbugEIJ-h"}},{"cell_type":"code","source":["'''\n","Q3 - (d)\n","Train your Seq2Seq model and plot losses and perplexities.\n","Upon successful training, the test perplexity should be less than 2.\n","You may use visualization libraries for plotting and modify training options such as hyperparameters and optimizer.\n","\n","Based on the results from lSTM(GRU)-based and transformer-based Seq2Seq models,\n","briefly describe which approach is better and why.\n","'''"],"metadata":{"id":"s8XBEzSHaUdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["in_dim = dataset.input_lang.n_words\n","out_dim = dataset.output_lang.n_words\n","hid_dim = 256\n","ff_dim = 1024\n","n_enc_layers = 4\n","n_dec_layers = 4\n","n_layers = [n_enc_layers, n_dec_layers]\n","n_heads = 8\n","dropout = 0.1\n","\n","learning_rate=1e-2\n","N_EPOCHS = 100\n","valid_every=5\n","best_valid_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = TransSeq2Seq(in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout, device).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss(ignore_index = dataset.output_lang_pad)\n","# print(model)"],"metadata":{"id":"hdNx0Ol5ILbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train your model\n","for epoch in range(N_EPOCHS):\n","    \n","    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n","    \n","    print(f'Epoch: {epoch+1:02}')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    \n","    if epoch%valid_every==0:\n","        print(\"==========================\")\n","        valid_loss = evaluate(model, valid_dataloader, loss_fn)\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            model.decoder.t=0\n","            torch.save(model.state_dict(), 'transformer-model.pt')\n","\n","        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"],"metadata":{"id":"aES3_sBTIgnN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test your model\n","loaded_model = TransSeq2Seq(in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout, device).to(device)\n","loaded_model.load_state_dict(torch.load('transformer-model.pt'))\n","\n","test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n","print(f'\\t Test. Loss: {valid_loss:.3f} |  Test. PPL: {math.exp(valid_loss):7.3f}')"],"metadata":{"id":"4M6sUc-aJKP3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"gCswrEKrLeiQ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["Kz2VM-9MIyKe","t07UOwbpH7CZ","KqnvbugEIJ-h"],"name":"hw4_translation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}